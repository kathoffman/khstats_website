<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rstats | KHstats</title>
    <link>/tags/rstats/</link>
      <atom:link href="/tags/rstats/index.xml" rel="self" type="application/rss+xml" />
    <description>rstats</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 10 Oct 2020 21:13:14 -0500</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>rstats</title>
      <link>/tags/rstats/</link>
    </image>
    
    <item>
      <title>Become a Superlearner! An Illustrated Guide to Superlearning</title>
      <link>/blog/sl/superlearning/</link>
      <pubDate>Sat, 10 Oct 2020 21:13:14 -0500</pubDate>
      <guid>/blog/sl/superlearning/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;blockquote&gt;
&lt;p&gt;Why use &lt;em&gt;one&lt;/em&gt; machine learning algorithm when you could use all of them?! This post contains a step-by-step walkthrough of how to build a superlearner prediction algorithm in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;
HTML Image as link
&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;img alt=&#34;cheatsheet&#34; src=&#34;/img/Superlearning.jpg&#34;  
         width=100%&#34;&gt;
&lt;figcaption&gt;
&lt;strong&gt;&lt;em&gt;A Visual Guide…&lt;/em&gt;&lt;/strong&gt; Over the winter, I read &lt;a href=&#34;https://www.springer.com/gp/book/9781441997814&#34;&gt;&lt;em&gt;Targeted Learning&lt;/em&gt;&lt;/a&gt; by Mark van der Laan and Sherri Rose. This “visual guide” I made for &lt;em&gt;Chapter 3: Superlearning&lt;/em&gt; by Rose, van der Laan, and Eric Polley is a condensed version of the following tutorial. It is available as an &lt;a href=&#34;https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/Superlearner.pdf&#34;&gt;8.5x11&#34; pdf on Github&lt;/a&gt;, should you wish to print it out for reference (or desk decor).
&lt;/figcaption&gt;
&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;div id=&#34;supercuts-of-superlearning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Supercuts of superlearning&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Superlearning&lt;/strong&gt; is a technique for prediction that involves &lt;strong&gt;combining many individual statistical algorithms&lt;/strong&gt; (commonly called “data-adaptive” or “machine learning” algorithms) to &lt;strong&gt;create a new, single prediction algorithm&lt;/strong&gt; that is expected to &lt;strong&gt;perform at least as well as any of the individual algorithms&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The superlearner algorithm “decides” how to combine, or weight, the individual algorithms based upon how well each one &lt;strong&gt;minimizes a specified loss function&lt;/strong&gt;, for example, the mean squared error (MSE). This is done using cross-validation to avoid overfitting.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The motivation for this type of “ensembling” is that &lt;strong&gt;a mix of multiple algorithms may be more optimal for a given data set than any single algorithm&lt;/strong&gt;. For example, a tree based model averaged with a linear model (e.g. random forests and LASSO) could smooth some of the model’s edges to improve predictive performance.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Superlearning is also called stacking, stacked generalizations, and weighted ensembling by different specializations within the realms of statistics and data science.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/img/spiderman_meme.jpg&#34; style=&#34;width:42.0%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;superlearning-step-by-step&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Superlearning, step by step&lt;/h1&gt;
&lt;p&gt;First I’ll go through the algorithm one step at a time using a simulated data set.&lt;/p&gt;
&lt;div id=&#34;initial-set-up-load-libraries-set-seed-simulate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initial set-up: Load libraries, set seed, simulate data&lt;/h2&gt;
&lt;p&gt;For simplicity I’ll show the concept of superlearning using only four variables (AKA features or predictors) to predict a continuous outcome. Let’s first simulate a continuous outcome, &lt;code&gt;y&lt;/code&gt;, and four potential predictors, &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, &lt;code&gt;x3&lt;/code&gt;, and &lt;code&gt;x4&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(kableExtra)
set.seed(7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 5000
obs &amp;lt;- tibble(
  id = 1:n,
  x1 = rnorm(n),
  x2 = rbinom(n, 1, plogis(10*x1)),
  x3 = rbinom(n, 1, plogis(x1*x2 + .5*x2)),
  x4 = rnorm(n, mean=x1*x2, sd=.5*x3),
  y = x1 + x2 + x2*x3 + sin(x4)
)
kable(head(obs), digits=3, caption = &amp;quot;Simulated data set&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-2&#34;&gt;Table 1: &lt;/span&gt;Simulated data set
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
id
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x3
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x4
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
y
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.287
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.385
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.270
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.197
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.197
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.694
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.694
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.412
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.541
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.928
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.971
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.971
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.947
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.160
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.107
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34; &gt;
&lt;strong&gt;Step 1: Split data into K folds
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step1.png&#34; style=&#34;width:50.0%&#34; /&gt;
The superlearner algorithm relies on K-fold cross-validation (CV) to avoid overfitting. We will start this process by splitting the data into 10 folds. The easiest way to do this is by creating indices for each CV fold.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- 10 # 10 fold cv
cv_index &amp;lt;- sample(rep(1:k, each = n/k)) # create indices for each CV fold. We need each fold K to contain n (all the rows of our data set) divided by k rows. in our example this is 5000/10 = 500 rows in each fold&lt;/code&gt;&lt;/pre&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 2: Fit base learners for first CV-fold
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step2.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Recall that in K-fold CV, each fold serves as the validation set one time. In this first round of CV, we will train all of our base learners on all the CV folds (k = 1,2,…,9) &lt;em&gt;except&lt;/em&gt; for the very last one: &lt;code&gt;cv_index == 10&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The individual algorithms or &lt;strong&gt;base learners&lt;/strong&gt; that we’ll use here are three linear regressions with differently specified parameters:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Learner A&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y=\beta_0 + \beta_1 X_2 + \beta_2 X_4 + \epsilon\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Learner B&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_3 + \beta_4 sin(X_4) + \epsilon\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Learner C&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_1 X_2 + \beta_5 X_1 X_3 + \beta_6 X_2 X_3 + \beta_7 X_1 X_2 X_3 + \epsilon\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_train_1 &amp;lt;- obs[-which(cv_index == 10),] # make a data set that contains all observations except those in k=1
fit_1a &amp;lt;- glm(y ~ x2 + x4, data=cv_train_1) # fit the first linear regression on that training data
fit_1b &amp;lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train_1) # second LR fit on the training data
fit_1c &amp;lt;- glm(y ~ x1*x2*x3, data=cv_train_1) # and the third LR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am &lt;em&gt;only&lt;/em&gt; using the linear regressions so that code for running more complicated regressions does not take away from understanding the general superlearning algorithm.&lt;/p&gt;
&lt;p&gt;Superlearning actually works best if you use a diverse set, or &lt;strong&gt;superlearner library&lt;/strong&gt;, of base learners. For example, instead of three linear regressions, we could use a least absolute shrinkage estimator (LASSO), random forest, and multivariate adaptive splines (MARS). Any parametric or non-parametric supervised machine learning algorithm can be included as a base learner.&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 3: Obtain predictions for first CV-fold
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step3.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can then get use our validation data, &lt;code&gt;cv_index == 10&lt;/code&gt;, to obtain our first set of cross-validated predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_valid_1 &amp;lt;- obs[which(cv_index == 10),] # make a data set that only contains observations except in k=10
pred_1a &amp;lt;- predict(fit_1a, newdata = cv_valid_1) # use that data set as the validation for all the models in the SL library
pred_1b &amp;lt;- predict(fit_1b, newdata = cv_valid_1) 
pred_1c &amp;lt;- predict(fit_1c, newdata = cv_valid_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we have 5000 &lt;code&gt;obs&lt;/code&gt;ervations, that gives us three vectors of length 500: a set of predictions for each of our Learners A, B, and C.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(pred_1a) # double check we only have n/k predictions ...we do :-)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(head(cbind(pred_1a, pred_1b, pred_1c)), digits= 2, caption = &amp;quot;First CV round of predictions&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-6&#34;&gt;Table 2: &lt;/span&gt;First CV round of predictions
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_1a
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_1b
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_1c
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.34
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.10
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.98
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.78
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.29
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.83
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 4: Obtain CV predictions for entire data set
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step4.png&#34; style=&#34;width:32.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We’ll want to get those predictions for &lt;em&gt;every&lt;/em&gt; fold. So, using your favorite &lt;code&gt;for&lt;/code&gt; loop, &lt;code&gt;apply&lt;/code&gt; statement, or &lt;code&gt;map&lt;/code&gt;ping function, fit the base learners and obtain predictions for each of them, so that there are 1000 predictions – one for every point in &lt;code&gt;obs&lt;/code&gt;ervations.&lt;/p&gt;
&lt;p&gt;The way I chose to code this was to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;make a generic function that combines Step 2 (base learners fit to the training data) and Step 3 (predictions on the validation data)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;map_dfr()&lt;/code&gt; from the &lt;code&gt;purrr&lt;/code&gt; package to repeat over all 10 CV folds and then save the results in a new data frame.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_folds &amp;lt;- as.list(1:k)
names(cv_folds) &amp;lt;- paste0(&amp;quot;fold&amp;quot;,1:k)

get_preds &amp;lt;- function(fold){   # function that does the same procedure as step 2 and 3 for any CV fold
  cv_train &amp;lt;- obs[-which(cv_index == fold),]  # make a training data set that contains all data except fold k
  fit_a &amp;lt;- glm(y ~ x2 + x4, data=cv_train)  # fit all the base learners to that data
  fit_b &amp;lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=cv_train)
  fit_c &amp;lt;- glm(y ~ x1*x2*x3, data=cv_train)
  cv_valid &amp;lt;- obs[which(cv_index == fold),]  # make a validation data set that only contains data from fold k
  pred_a &amp;lt;- predict(fit_a, newdata = cv_valid)  # obtain predictions from all the base learners for that validation data
  pred_b &amp;lt;- predict(fit_b, newdata = cv_valid)
  pred_c &amp;lt;- predict(fit_c, newdata = cv_valid)
  return(data.frame(&amp;quot;obs_id&amp;quot; = cv_valid$id, &amp;quot;cv_fold&amp;quot; = fold, pred_a, pred_b, pred_c))  # save the predictions and the ids of the observations in a data frame
}

cv_preds &amp;lt;- purrr::map_dfr(cv_folds, ~get_preds(fold = .x)) # map_dfr loops through every fold (1:k) and binds the rows of the listed results together

cv_preds %&amp;gt;% arrange(obs_id) %&amp;gt;% head() %&amp;gt;% kable(digits=2, caption = &amp;quot;All CV predictions for all three base learners&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-7&#34;&gt;Table 3: &lt;/span&gt;All CV predictions for all three base learners
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
obs_id
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
cv_fold
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_a
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_b
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_c
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.42
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.28
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.81
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.69
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.97
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1…6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.94
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 5: Choose and compute loss function of interest via metalearner
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step5.png&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is the key step of the superlearner algorithm: we will use a new learner, a &lt;strong&gt;metalearner&lt;/strong&gt;, to take information from all of the base learners and create that new algorithm.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now that we have cross-validated predictions for every observation in the data set, we want to merge those CV predictions back into our main data set…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs_preds &amp;lt;- 
  full_join(obs, cv_preds, by=c(&amp;quot;id&amp;quot; = &amp;quot;obs_id&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…so that we can minimize a final loss function of interest between the true outcome and each CV prediction. This is how we’re going to optimize our overall prediction algorithm: we want to make sure we’re “losing the least” in the way we combine our base learners’ predictions to ultimately make final predictions. We can do this efficiently by choosing a new learner, a metalearner, which reflects the final loss function of interest.&lt;/p&gt;
&lt;p&gt;For simplicity, we’ll use another linear regression as our metalearner. Using a linear regression as a metalearner will minimize the Cross-Validated Mean Squared Error (CV-MSE) when combining the base learner predictions. Note that we could use a variety of parametric or non-parametric regressions to minimize the CV-MSE.&lt;/p&gt;
&lt;p&gt;No matter what metalearner we choose, the predictors will always be the cross-validated predictions from each base learner, and the outcome will always be the true outcome, &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sl_fit &amp;lt;- glm(y ~ pred_a + pred_b + pred_c, data = obs_preds)
kable(broom::tidy(sl_fit), digits=3, caption = &amp;quot;Metalearner regression coefficients&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-9&#34;&gt;Table 4: &lt;/span&gt;Metalearner regression coefficients
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.003
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.002
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.447
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.148
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pred_a
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.017
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4.739
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pred_b
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.854
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
128.241
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
pred_c
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.165
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.005
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30.103
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This metalearner provides us with the coefficients, or weights, to apply to each of the base learners. In other words, if we have a set of predictions from Learner A, B, and C, we can obtain our best possible predictions by starting with an intercept of -0.003, then adding -0.017 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; predictions from Learner A, 0.854 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; predictions from Learner B, and 0.165 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; predictions from Learner C.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For more information on the metalearning step, check out the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 6: Fit base learners on entire data set
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step6.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;After we fit the metalearner, we officially have our superlearner algorithm, so it’s time to input data and obtain predictions! To implement the algorithm and obtain final predictions, we first need to fit the base learners on the full data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_a &amp;lt;- glm(y ~ x2 + x4, data=obs)
fit_b &amp;lt;- glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=obs)
fit_c &amp;lt;- glm(y ~ x1*x2*x3, data=obs)&lt;/code&gt;&lt;/pre&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 7: Obtain predictions from each base learner on entire data set
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step7.png&#34; style=&#34;width:40.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We’ll use &lt;em&gt;those&lt;/em&gt; base learner fits to get predictions from each of the base learners for the entire data set, and then we will plug those predictions into the metalearner fit. Remember, we were previously using cross-validated predictions, rather than fitting the base learners on the whole data set. This was to avoid overfitting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred_a &amp;lt;- predict(fit_a)
pred_b &amp;lt;- predict(fit_b)
pred_c &amp;lt;- predict(fit_c)
full_data_preds &amp;lt;- tibble(pred_a, pred_b, pred_c)&lt;/code&gt;&lt;/pre&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 8: Use metalearner fit to weight base learners
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_steps/step8.png&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Once we have the predictions from the full data set, we can input them to the metalearner, where the output will be a final prediction for &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sl_predictions &amp;lt;- predict(sl_fit, newdata = full_data_preds)
kable(head(sl_predictions), col.names = &amp;quot;sl_predictions&amp;quot;, digits= 2, caption = &amp;quot;Final SL predictions (manual)&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-12&#34;&gt;Table 5: &lt;/span&gt;Final SL predictions (manual)
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sl_predictions
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.44
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.79
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.71
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.02
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.03
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And… that’s it! Those are our superlearner predictions for the full data set.&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 9: Obtaining predictions on new data
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;We can now modify Step 7 and Step 8 to accommodate any new observation(s):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.Use the fits from each base learner to obtain base learner predictions for the new observation(s).&lt;br&gt;2. Plug those base learner predictions into the metalearner fit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can generate a single &lt;code&gt;new_obs&lt;/code&gt;ervation to see how this would work in practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_obs &amp;lt;- tibble(x1 = .5, x2 = 0, x3 = 0, x4 = -3)
new_pred_a &amp;lt;- predict(fit_a, new_obs)
new_pred_b &amp;lt;- predict(fit_b, new_obs)
new_pred_c &amp;lt;- predict(fit_c, new_obs)
new_pred_df &amp;lt;- tibble(&amp;quot;pred_a&amp;quot; = new_pred_a, &amp;quot;pred_b&amp;quot; = new_pred_b, &amp;quot;pred_c&amp;quot; = new_pred_c)
predict(sl_fit, newdata = new_pred_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         1 
## 0.1181052&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our superlearner model predicts that an observation with predictors &lt;span class=&#34;math inline&#34;&gt;\(x1=.5\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x3=0\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(x4=-3\)&lt;/span&gt; will have an outcome of 0.118. Good to know!&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:#c30a0a&#34;&gt;
&lt;strong&gt;Step 10 and beyond…
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;We could compute the MSE of the ensemble superlearner predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sl_mse &amp;lt;- mean((obs$y - sl_predictions)^2)
sl_mse&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01927392&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could also add more algorithms to our base learner library (we definitely should, since we only used linear regressions!), and we could write functions to tune these algorithms’ hyperparameters over various grids. For example, if we were to include random forest in our library, we may want to tune over a number of trees and maximum bucket sizes.&lt;/p&gt;
&lt;p&gt;We can then cross-validate this entire process to evaluate the predictive performance of our superlearner algorithm. Alternatively, we could leave a hold-out training data set to evaluate the performance.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-superlearner-package&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using the &lt;code&gt;SuperLearner&lt;/code&gt; package&lt;/h1&gt;
&lt;p&gt;Or… we could use a package and avoid all the hand-coding. Here is how you would build an ensemble superlearner for our data with the base learner libraries of &lt;code&gt;ranger&lt;/code&gt; (random forests), &lt;code&gt;glmnet&lt;/code&gt; (LASSO, by default), and &lt;code&gt;earth&lt;/code&gt; (MARS) using the &lt;code&gt;SuperLearner&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(SuperLearner)
x_df &amp;lt;- obs %&amp;gt;% select(x1:x4) %&amp;gt;% as.data.frame()
sl_fit &amp;lt;- SuperLearner(Y = obs$y, X = x_df, family = gaussian(),
                     SL.library = c(&amp;quot;SL.ranger&amp;quot;, &amp;quot;SL.glmnet&amp;quot;, &amp;quot;SL.earth&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can specify the metalearner with the &lt;code&gt;method&lt;/code&gt; argument. The default is &lt;a href=&#34;##non-negative-least-squares&#34;&gt;Non-Negative Least Squares&lt;/a&gt; (NNLS).&lt;/p&gt;
&lt;div id=&#34;cv-risk-and-coefficient-weights&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;CV-Risk and Coefficient Weights&lt;/h2&gt;
&lt;p&gt;We can examine the cross-validated &lt;code&gt;Risk&lt;/code&gt; (loss function), and the &lt;code&gt;Coef&lt;/code&gt;ficient (weight) given to each of the models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sl_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:  
## SuperLearner(Y = obs$y, X = x_df, family = gaussian(), SL.library = c(&amp;quot;SL.ranger&amp;quot;,  
##     &amp;quot;SL.glmnet&amp;quot;, &amp;quot;SL.earth&amp;quot;)) 
## 
## 
##                      Risk      Coef
## SL.ranger_All 0.013278476 0.1619231
## SL.glmnet_All 0.097149642 0.0000000
## SL.earth_All  0.003168299 0.8380769&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this summary we can see that the CV-risk (the default risk is MSE) in this library of base learners is smallest for &lt;code&gt;SL.Earth&lt;/code&gt;. This translates to the largest coefficient, or weight, given to the predictions from &lt;code&gt;earth&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The LASSO model implemented by &lt;code&gt;glmnet&lt;/code&gt; has the largest CV-risk, and after the metalearning step, those predictions receive a coefficient, or weight, of 0. This means that the predictions from LASSO will not be incorporated into the final predictions at all.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;obtaining-the-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Obtaining the predictions&lt;/h2&gt;
&lt;p&gt;We can extract the predictions easily via the &lt;code&gt;SL.predict&lt;/code&gt; element of the &lt;code&gt;SuperLearner&lt;/code&gt; fit object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(head(sl_fit$SL.predict), digits=2, col.names = &amp;quot;sl_predictions&amp;quot;, caption = &amp;quot;Final SL predictions (package)&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-17&#34;&gt;Table 6: &lt;/span&gt;Final SL predictions (package)
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sl_predictions
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.29
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.19
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.68
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.87
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.97
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-1.08
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-validated-superlearner&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cross-validated Superlearner&lt;/h2&gt;
&lt;p&gt;Recall that we can cross-validate the entire model fitting process to evaluate the predictive performance of our superlearner algorithm. This is easy with the function &lt;code&gt;CV.SuperLearner()&lt;/code&gt;. Beware, this gets computationally burdensome very quickly!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_sl_fit &amp;lt;- CV.SuperLearner(Y = obs$y, X = x_df, family = gaussian(),
                     SL.library = c(&amp;quot;SL.ranger&amp;quot;, &amp;quot;SL.glmnet&amp;quot;, &amp;quot;SL.earth&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more information on the &lt;code&gt;SuperLearner&lt;/code&gt; package, take a look at this &lt;a href=&#34;https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html&#34;&gt;vignette&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;alternative-packages-to-superlearn&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Alternative packages to superlearn&lt;/h2&gt;
&lt;p&gt;Other packages freely available in &lt;code&gt;R&lt;/code&gt; that can be used to implement the superlearner algorithm include &lt;code&gt;sl3&lt;/code&gt; (an update to the older &lt;code&gt;Superlearner&lt;/code&gt; package), &lt;code&gt;h2o&lt;/code&gt;, &lt;code&gt;ml3&lt;/code&gt;, and &lt;code&gt;caretEnsemble&lt;/code&gt;. I previously wrote a &lt;a href=&#34;https://www.khstats.com/blog/sl3_demo/sl/&#34;&gt;brief demo&lt;/a&gt; on using &lt;code&gt;sl3&lt;/code&gt; for an NYC R-Ladies demo.&lt;/p&gt;
&lt;p&gt;Python aficionados might find this &lt;a href=&#34;https://machinelearningmastery.com/super-learner-ensemble-in-python/&#34;&gt;blog post&lt;/a&gt; useful. I have never performed superlearning in Python, but if I had to, I would probably try &lt;code&gt;h2o&lt;/code&gt; first. H2o is available in many programming languages and their Chief Machine Learning Scientist, Erin Ledell, was an author of the original &lt;code&gt;SuperLearner&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;manually-computing-the-mse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Manually computing the MSE&lt;/h3&gt;
&lt;p&gt;Let’s say we have chosen our loss function of interest to be the Mean Squared Error (MSE). We could first compute the squared error &lt;span class=&#34;math inline&#34;&gt;\((y - \hat{y})^2\)&lt;/span&gt; for each CV prediction A, B, and C.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_sq_error &amp;lt;-
  obs_preds %&amp;gt;%
  mutate(cv_sqrd_error_a = (y-pred_a)^2,   # compute squared error for each observation
         cv_sqrd_error_b = (y-pred_b)^2,
         cv_sqrd_error_c = (y-pred_c)^2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_sq_error %&amp;gt;% 
  pivot_longer(c(cv_sqrd_error_a, cv_sqrd_error_b, cv_sqrd_error_c), # make the CV squared errors long form for plotting
               names_to = &amp;quot;base_learner&amp;quot;,
               values_to = &amp;quot;squared_error&amp;quot;) %&amp;gt;%
  mutate(base_learner = toupper(str_remove(base_learner, &amp;quot;cv_sqrd_error_&amp;quot;))) %&amp;gt;%
  ggplot(aes(base_learner, squared_error, col=base_learner)) + # make box plots
  geom_boxplot() +
  theme_bw() +
  guides(col=F) +
  labs(x = &amp;quot;Base Learner&amp;quot;, y=&amp;quot;Squared Error&amp;quot;, title=&amp;quot;Squared Errors of Learner A, B, and C&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/sl/superlearning_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And then take the mean of those three cross-validated squared error columns, grouped by &lt;code&gt;cv_fold&lt;/code&gt;, to get the CV-MSE for each fold.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_risks &amp;lt;-
  cv_sq_error %&amp;gt;%
  group_by(cv_fold) %&amp;gt;%
  summarise(cv_mse_a = mean(cv_sqrd_error_a),
            cv_mse_b = mean(cv_sqrd_error_b),
            cv_mse_c = mean(cv_sqrd_error_c)
            )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_risks %&amp;gt;%
  pivot_longer(cv_mse_a:cv_mse_c,
               names_to = &amp;quot;base_learner&amp;quot;,
               values_to = &amp;quot;mse&amp;quot;) %&amp;gt;%
  mutate(base_learner = toupper(str_remove(base_learner,&amp;quot;cv_mse_&amp;quot;)))  %&amp;gt;%
  ggplot(aes(cv_fold, mse, col=base_learner)) +
  geom_point() +
  theme_bw()  +
    scale_x_continuous(breaks = 1:10) +
  labs(x = &amp;quot;Cross-Validation (CV) Fold&amp;quot;, y=&amp;quot;Mean Squared Error (MSE)&amp;quot;, col = &amp;quot;Base Learner&amp;quot;, title=&amp;quot;CV-MSEs for Base Learners A, B, and C&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/sl/superlearning_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that across each fold, Learner B consistently has an MSE around 0.02, while Learner C hovers around 0.1, and Learner A varies between 0.35 and .45. We can take another mean to get the overall CV-MSE for each learner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cv_risks %&amp;gt;%
  select(-cv_fold) %&amp;gt;%
  summarise_all(mean) %&amp;gt;%
  kable(digits=2, caption = &amp;quot;CV-MSE for each base learner&amp;quot;) %&amp;gt;%
  kable_styling(position = &amp;quot;center&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-22&#34;&gt;Table 7: &lt;/span&gt;CV-MSE for each base learner
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
cv_mse_a
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
cv_mse_b
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
cv_mse_c
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.11
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The base learner that performs the best using our chosen loss function of interest is clearly Learner B. We can see from our data simulation code why this is true – Learner B is almost exactly the mimicking the data generating mechanism of &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our results align with the linear regression fit from our metalearning step; Learner B predictions received a much larger coefficient relative to Learners A and C.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;discrete-superlearner&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Discrete Superlearner&lt;/h3&gt;
&lt;p&gt;We &lt;em&gt;could&lt;/em&gt; stop after minimizing our loss function (MSE) and fit Learner B to our full data set, and that would be called using the &lt;strong&gt;discrete superlearner&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;discrete_sl_predictions &amp;lt;- predict(glm(y ~ x1 + x2 + x1*x3 + sin(x4), data=obs))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, we can almost always create an even better prediction algorithm if we use information from &lt;em&gt;all&lt;/em&gt; of the algorithms’ CV predictions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-a-metalearner&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Choosing a metalearner&lt;/h3&gt;
&lt;p&gt;In the &lt;a href=&#34;#references&#34;&gt;Reference&lt;/a&gt; papers on superlearning, the metalearner which yields the best results theoretically and in practice is a &lt;strong&gt;convex combination optimization&lt;/strong&gt; of learners. This means fitting the following regression, where &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\alpha_3\)&lt;/span&gt; are all non-negative and sum to 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathrm{E}[Y|\hat{Y}_{LrnrA},\hat{Y}_{LrnrB},\hat{Y}_{LrnrC}] = \alpha_1\hat{Y}_{LrnrA} + \alpha_2\hat{Y}_{LrnrB} + \alpha_3\hat{Y}_{LrnrC}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The default in the &lt;code&gt;Superlearner&lt;/code&gt; package is to fit a non-negative least squares (NNLS) regression. NNLS fits the above equation where the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;’s must be greater than or equal to 1 but do not necessarily sum to 1. The package then reweights the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;’s to force them to sum to 1. This makes the weights a convex combination, but may not yield the same optimal results as an initial convex combination optimization.&lt;/p&gt;
&lt;p&gt;The metalearner should change with the goals of the prediction algorithm and the loss function of interest. In these examples it is the MSE, but if the goal is to build a prediction algorithm that is best for binary classification, the loss function of interest may be the rank loss, or &lt;span class=&#34;math inline&#34;&gt;\(1-AUC\)&lt;/span&gt;. It is outside the scope of this post, but for more information, I recommend this &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912128/&#34;&gt;paper&lt;/a&gt; by Erin Ledell on maximizing the Area Under the Curve (AUC) with superlearner algorithms.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-visual-guide-for-superlearning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Another visual guide for superlearning&lt;/h3&gt;
&lt;p&gt;The steps of the superlearner algorithm are summarized nicely in this graphic in Chapter 3 of the &lt;em&gt;Targeted Learning&lt;/em&gt; book:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/sl_diagram.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coming-soon-when-prediction-is-not-the-end-goal&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coming soon… when prediction is not the end goal&lt;/h1&gt;
&lt;p&gt;When prediction is not the end goal, superlearning combines well with semi-parametric estimation methods for statistical inference (for example, Targeted Maximum Likelihood Estimation (TMLE)). This allows the use of flexible models and minimal assumptions placed on the distribution of the data.&lt;/p&gt;
&lt;p&gt;I made a similar &lt;a href=&#34;https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/TMLE.pdf&#34;&gt;visual guide for TMLE&lt;/a&gt;. If you found this superlearning tutorial helpful, check back here later for another one on TMLE. If you’re curious about TMLE in the meantime, I really like &lt;a href=&#34;https://migariane.github.io/TMLE.nb.html&#34;&gt;this tutorial&lt;/a&gt; by Miguel Angel Luque Fernandez.&lt;/p&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;
HTML Image as link
&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;a href=&#34;https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/TMLE.pdf&#34;&gt;
&lt;img alt=&#34;cheatsheet&#34; src=&#34;/img/TMLE.jpg&#34;
         width=100%&#34;&gt;
&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Acknowledgments&lt;/h1&gt;
&lt;p&gt;Thank you to Eric Polley, Iván Díaz, Nick Williams, Anjile An, and Adam Peterson for very helpful content (and design!) suggestions for this post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;MJ Van der Laan, EC Polley, AE Hubbard, Super Learner, Statistical applications in genetics and molecular, 2007&lt;/p&gt;
&lt;p&gt;Polley, Eric. “Chapter 3: Superlearning.” Targeted Learning: Causal Inference for Observational and Experimental Data, by M. J. van der. Laan and Sherri Rose, Springer, 2011.&lt;/p&gt;
&lt;p&gt;Polley E, LeDell E, Kennedy C, van der Laan M. Super Learner: Super Learner Prediction. 2016 URL &lt;a href=&#34;https://CRAN.R-project.org/package=SuperLearner&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=SuperLearner&lt;/a&gt;. R package version 2.0-22.&lt;/p&gt;
&lt;p&gt;Naimi AI, Balzer LB. Stacked generalization: an introduction to super learning. &lt;em&gt;Eur J Epidemiol.&lt;/em&gt; 2018;33(5):459-464. &lt;a href=&#34;doi:10.1007/s10654-018-0390-z&#34; class=&#34;uri&#34;&gt;doi:10.1007/s10654-018-0390-z&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;LeDell, E. (2015). Scalable Ensemble Learning and Computationally Efficient Variance Estimation. UC Berkeley. ProQuest ID: LeDell_berkeley_0028E_15235. Merritt ID: ark:/13030/m5wt1xp7. Retrieved from &lt;a href=&#34;https://escholarship.org/uc/item/3kb142r2&#34; class=&#34;uri&#34;&gt;https://escholarship.org/uc/item/3kb142r2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;M. Petersen and L. Balzer. Introduction to Causal Inference. UC Berkeley, August 2014. &lt;a href=&#34;www.ucbbiostat.com&#34;&gt;www.ucbbiostat.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Session Info&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] SuperLearner_2.0-26 nnls_1.4            kableExtra_1.1.0   
##  [4] forcats_0.5.0       stringr_1.4.0       dplyr_1.0.2        
##  [7] purrr_0.3.4         readr_1.3.1         tidyr_1.1.2        
## [10] tibble_3.0.3        ggplot2_3.3.2       tidyverse_1.3.0    
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.4.1         jsonlite_1.6.1     viridisLite_0.3.0  foreach_1.5.0     
##  [5] modelr_0.1.6       Formula_1.2-3      assertthat_0.2.1   highr_0.8         
##  [9] cellranger_1.1.0   yaml_2.2.1         pillar_1.4.6       backports_1.1.8   
## [13] lattice_0.20-38    glue_1.4.2         digest_0.6.25      rvest_0.3.5       
## [17] colorspace_1.4-1   htmltools_0.4.0    Matrix_1.2-18      pkgconfig_2.0.3   
## [21] broom_0.7.0        earth_5.1.2        haven_2.2.0        bookdown_0.19     
## [25] scales_1.1.1       webshot_0.5.2      ranger_0.12.1      TeachingDemos_2.12
## [29] generics_0.0.2     farver_2.0.3       ellipsis_0.3.1     withr_2.2.0       
## [33] cli_2.0.2          magrittr_1.5       crayon_1.3.4       readxl_1.3.1      
## [37] evaluate_0.14      fs_1.4.1           fansi_0.4.1        xml2_1.3.0        
## [41] cabinets_0.5.0     blogdown_0.19      tools_3.6.3        hms_0.5.3         
## [45] lifecycle_0.2.0    munsell_0.5.0      reprex_0.3.0       glmnet_3.0-2      
## [49] plotrix_3.7-7      compiler_3.6.3     rlang_0.4.7        plotmo_3.5.7      
## [53] grid_3.6.3         iterators_1.0.12   rstudioapi_0.11    labeling_0.3      
## [57] rmarkdown_2.1      gtable_0.3.0       codetools_0.2-16   DBI_1.1.0         
## [61] R6_2.4.1           lubridate_1.7.9    knitr_1.28         shape_1.4.4       
## [65] stringi_1.4.6      Rcpp_1.0.5         vctrs_0.3.4        dbplyr_1.4.3      
## [69] tidyselect_1.1.0   xfun_0.14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Customizable correlation plots in R</title>
      <link>/blog/corr-plots/corr-plots/</link>
      <pubDate>Sat, 14 Mar 2020 21:13:14 -0500</pubDate>
      <guid>/blog/corr-plots/corr-plots/</guid>
      <description>


&lt;hr /&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;TL;DR&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you’re ever felt limited by correlogram packages in &lt;code&gt;R&lt;/code&gt;, this post will show you how to write your own function to tidy the many correlations into a &lt;code&gt;ggplot2&lt;/code&gt;-friendly form for plotting.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;By the end, you will be able to run one function to get a tidied data frame of correlations:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;% head() %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sig_p&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_if_sig&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_if_sig&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;You can then run &lt;code&gt;ggplot2&lt;/code&gt; code on this data to make your own correlation heat maps.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you just want the code, &lt;a href=&#34;#just-the-code&#34;&gt;skip to the end&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;less-customizable-options&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Less-customizable options&lt;/h1&gt;
&lt;p&gt;I really appreciate some of the packages and functions that allow me to make correlation plots super quickly using &lt;code&gt;R&lt;/code&gt;. Here are a few examples:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrplot::corrplot(cor(mtcars))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrgram::corrgram(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;seriation&amp;#39;:
##   method         from 
##   reorder.hclust gclus&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggcorrplot::ggcorrplot(cor(mtcars))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All of these are nice, but none of them are ultimately as customizable as I need them to be. I’ll next show how you can bypass using someone else’s function constraints to prepare correlations in your data in a &lt;code&gt;ggplot2&lt;/code&gt;-friendly format.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-the-correlations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting the correlations&lt;/h1&gt;
&lt;p&gt;We could use the base &lt;code&gt;R&lt;/code&gt; function &lt;code&gt;cor()&lt;/code&gt; to get our correlations, but I do not like the defaults for missing data. Instead, I use Frank Harrell’s &lt;code&gt;Hmisc::rcorr()&lt;/code&gt; function for two reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;it drops missing pairs as the default&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it returns p-values, so you only need one function to get both the correlation coefficient and matching p-value&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s load the libraries we’ll need for this, which are &lt;code&gt;knitr&lt;/code&gt; for showing tables using &lt;code&gt;kable&lt;/code&gt;, and &lt;code&gt;tidyverse&lt;/code&gt; (we’ll specifically use &lt;code&gt;tidyr&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;tibble&lt;/code&gt; and &lt;code&gt;purrr&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(knitr)
library(tidyverse, warn.conflict=F)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s look at our output from our correlation function we’ll use, &lt;code&gt;Hmisc::rcorr()&lt;/code&gt;. It requires the input to be a matrix, and outputs a list of three matrices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_cor &amp;lt;- Hmisc::rcorr(as.matrix(mtcars))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These three matrices include the correlation coefficient (default is Pearson’s), &lt;code&gt;r&lt;/code&gt;, the p-value, &lt;code&gt;P&lt;/code&gt;, and the number of observations used for each correlation, &lt;code&gt;n&lt;/code&gt;. Let’s turn each matrix into a &lt;code&gt;data frame&lt;/code&gt; and look at the top six rows with &lt;code&gt;head&lt;/code&gt; and &lt;code&gt;kable&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The correlation coefficients, &lt;code&gt;r&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(mtcars_cor$r) %&amp;gt;% head() %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;disp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;drat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qsec&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;vs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gear&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;carb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4186840&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6640389&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5998324&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4802848&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5509251&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912421&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8108118&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5226070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4926866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5269883&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4336979&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7104159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5555692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3949769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7082234&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7230967&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2432043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1257043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7498125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0912048&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4402785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7127111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6996101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0907898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1747159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5549157&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6924953&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5832870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4276059&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The p-values, &lt;code&gt;P&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(mtcars_cor$P) %&amp;gt;% head() %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;disp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;drat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qsec&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;vs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gear&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;carb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000002&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000178&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0170820&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000342&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0002850&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0054009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0010844&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000082&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0003661&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0021512&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0041733&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0019423&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000053&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0131440&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000052&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0003662&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0009636&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0252679&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0099888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.15e-05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000058&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000029&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1798309&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4930119&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.2e-06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.3e-06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0099888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.80e-06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6195826&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0116755&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000047&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000084&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6211834&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000415&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000048&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3388683&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0009798&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0000113&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0004587&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0146386&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The number of observations, &lt;code&gt;n&lt;/code&gt;. There are no missing data in the &lt;code&gt;mtcars&lt;/code&gt; data set so there are 32 pairs used for all correlations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(mtcars_cor$n) %&amp;gt;% head(n=3) %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;disp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;drat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qsec&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;vs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gear&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;carb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Next we can write a function that formats a &lt;code&gt;data frame&lt;/code&gt; correctly for &lt;code&gt;Hmisc::rcorr()&lt;/code&gt; and then turns each of the three elements of the list (&lt;code&gt;r&lt;/code&gt;,&lt;code&gt;n&lt;/code&gt; and &lt;code&gt;P&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors &amp;lt;- function(df) {
  M &amp;lt;- Hmisc::rcorr(as.matrix(df))
  # turn all three matrices (r, n, and P into a data frame)
  Mdf &amp;lt;- map(M, ~data.frame(.x))
  # return the three data frames in a list
  return(Mdf)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nothing too crazy happened in this function. Now we just have a list of three data frames. We can look at the the first element of our list using &lt;code&gt;first()&lt;/code&gt;, which shows us the correlations between all our variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;% first() %&amp;gt;% head() %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;disp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;drat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qsec&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;vs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gear&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;carb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4186840&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6640389&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5998324&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4802848&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5509251&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912421&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8108118&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5226070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4926866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5269883&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4336979&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7104159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5555692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3949769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7082234&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7230967&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2432043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1257043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7498125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0912048&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4402785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7127111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6996101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0907898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1747159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5549157&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6924953&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5832870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4276059&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;prep-the-correlations-for-ggplot2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Prep the correlations for &lt;code&gt;ggplot2&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The next step is to get the data ready for plotting with &lt;code&gt;ggplot2&lt;/code&gt;. We can keep the data in a list for now and use the &lt;code&gt;map()&lt;/code&gt; function from &lt;code&gt;purrr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, we need to move the rownames to their own column using &lt;code&gt;tibble::rownames_to_column()&lt;/code&gt;. The output of that looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;%
  map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
  # look at the first element of the list (r)
  first() %&amp;gt;%
  head() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mpg&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;disp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;hp&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;drat&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;wt&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qsec&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;vs&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;am&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;gear&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;carb&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4186840&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6640389&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5998324&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4802848&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5509251&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912421&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8108118&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5226070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4926866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5269883&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9020329&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4336979&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7104159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5912270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5555692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3949769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8324475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7909486&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7082234&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7230967&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.2432043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1257043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7498125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6999381&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7102139&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4487591&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0912048&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4402785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7127111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6996101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0907898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7824958&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8879799&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6587479&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7124406&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1747159&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5549157&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6924953&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5832870&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4276059&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Next, we can turn move of the columns to a single column called &lt;code&gt;measure2&lt;/code&gt; using &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;%
  map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
  # format each data set (r,P,n) long
  map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
  # look at the first element of the list (r)
  first() %&amp;gt;%
  head() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now, we’re ready to unlist our data by using &lt;code&gt;bind_rows()&lt;/code&gt;. This will turn our correlations into a very long data frame with all the rows from &lt;code&gt;r&lt;/code&gt;, then &lt;code&gt;n&lt;/code&gt;, then &lt;code&gt;P&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;%
  map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
  # format each data set (r,P,n) long
  map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
  # merge our three list elements by binding the rows
  bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;%
  head() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;id&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;r&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For &lt;code&gt;ggplot2&lt;/code&gt;, we’ll need to have &lt;code&gt;r&lt;/code&gt;, &lt;code&gt;n&lt;/code&gt;, and &lt;code&gt;p&lt;/code&gt; as their own column. We can use &lt;code&gt;pivot_longer()&lt;/code&gt; to do this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;%
  map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
  # format each data set (r,P,n) long
  map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
  # merge our three list elements by binding the rows
  bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;%
  pivot_wider(names_from = id, values_from = value) %&amp;gt;%
  head() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;P&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Finally, we can add a few columns that will potentially be useful later for making our correlation plots more informative. Let’s add columns that tell us whether the p-value was less than 0.05, and if so, give us back 1) the p-value and 2) the correlation coefficient, in case we want to label our plot with these values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors(mtcars) %&amp;gt;%
  map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
  # format each data set (r,P,n) long
  map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
  # merge our three list elements by binding the rows
  bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;%
  pivot_wider(names_from = id, values_from = value) %&amp;gt;%
  # change so everything is lower case
  rename(p = P) %&amp;gt;%
  mutate(sig_p = ifelse(p &amp;lt; .05, T, F),
           p_if_sig = ifelse(p &amp;lt;.05, p, NA),
           r_if_sig = ifelse(r &amp;lt;.05, r, NA)) %&amp;gt;%
  head() %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sig_p&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_if_sig&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_if_sig&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This seems like everything I think I’ll ever ever want to plot. Of course you could add more. At this point I turned my formatted correlations into a function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors &amp;lt;- function(df){
  cors(df) %&amp;gt;%
    map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
    map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
    bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;%
    pivot_wider(names_from = id, values_from = value) %&amp;gt;%
    rename(p = P) %&amp;gt;%
    mutate(sig_p = ifelse(p &amp;lt; .05, T, F),
           p_if_sig = ifelse(p &amp;lt;.05, p, NA),
           r_if_sig = ifelse(r &amp;lt;.05, r, NA)) 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can test the function works as expected:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;% head() %&amp;gt;% kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;measure1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;measure2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sig_p&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_if_sig&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;r_if_sig&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;cyl&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8521620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;disp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8475514&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hp&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00e-07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.7761684&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;drat&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6811719&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.78e-05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mpg&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;wt&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;TRUE&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00e+00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8676594&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting&lt;/h1&gt;
&lt;p&gt;We’re finally ready to plot our correlation heat maps in &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The simplest form of this plot only requires us to specify &lt;code&gt;measure1&lt;/code&gt; and &lt;code&gt;measure2&lt;/code&gt; on the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;-axis, respectively. Then we can map the correlation &lt;code&gt;r&lt;/code&gt; to the &lt;code&gt;fill&lt;/code&gt; &lt;code&gt;aes&lt;/code&gt;thetic, and add a tile as the &lt;code&gt;geom&lt;/code&gt;etry.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;%
  ggplot(aes(x = measure1, y = measure2, fill = r)) +
  geom_tile()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can make some minor aesthetic changes, such as the fill coloring scale, titles, and font family.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;%
  ggplot(aes(x = measure1, y = measure2, fill = r)) +
  geom_tile() +
  labs(x = NULL, y = NULL, fill = &amp;quot;Pearson&amp;#39;s\nCorrelation&amp;quot;, title=&amp;quot;Correlations in Mtcars&amp;quot;) +
  # map a red, white and blue color scale to correspond to -1:1 sequential gradient
  scale_fill_gradient2(mid=&amp;quot;#FBFEF9&amp;quot;,low=&amp;quot;#0C6291&amp;quot;,high=&amp;quot;#A63446&amp;quot;, limits=c(-1,1)) +
  theme_classic() +
  # remove excess space on x and y axes
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  # change global font to roboto
  theme(text=element_text(family=&amp;quot;Roboto&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can add the correlations for extra information. For this particular plot, I only added significant (p-value less than 0.05) correlations, using the column &lt;code&gt;r_if_sig&lt;/code&gt; that outputs from &lt;code&gt;formatted_cors()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;%
  ggplot(aes(measure1, measure2, fill=r, label=round(r_if_sig,2))) +
  geom_tile() +
  labs(x = NULL, y = NULL, fill = &amp;quot;Pearson&amp;#39;s\nCorrelation&amp;quot;, title=&amp;quot;Correlations in Mtcars&amp;quot;,
       subtitle=&amp;quot;Only significant Pearson&amp;#39;s correlation coefficients shown&amp;quot;) +
  scale_fill_gradient2(mid=&amp;quot;#FBFEF9&amp;quot;,low=&amp;quot;#0C6291&amp;quot;,high=&amp;quot;#A63446&amp;quot;, limits=c(-1,1)) +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  theme(text=element_text(family=&amp;quot;Roboto&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another version of this could involve squares with different sizes to denote strength of correlation using &lt;code&gt;geom_point&lt;/code&gt; with &lt;code&gt;shape&lt;/code&gt; set to a value from &lt;a href=&#34;http://www.sthda.com/english/wiki/ggplot2-point-shapes&#34;&gt;these available &lt;code&gt;geom_shape&lt;/code&gt;s&lt;/a&gt;. Make sure you take the absolute value of the correlation so that strong negative correlations can also be denoted larger.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;formatted_cors(mtcars) %&amp;gt;%
  ggplot(aes(measure1, measure2, col=r)) + ## to get the rect filled
  geom_tile(col=&amp;quot;black&amp;quot;, fill=&amp;quot;white&amp;quot;) +
  geom_point(aes(size = abs(r)), shape=15) +
  labs(x = NULL, y = NULL, col = &amp;quot;Pearson&amp;#39;s\nCorrelation&amp;quot;, title=&amp;quot;Correlations in Mtcars&amp;quot;) +
  theme_classic()+
  scale_color_gradient2(mid=&amp;quot;#FBFEF9&amp;quot;,low=&amp;quot;#0C6291&amp;quot;,high=&amp;quot;#A63446&amp;quot;, limits=c(-1,1))  +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  theme(text=element_text(family=&amp;quot;Roboto&amp;quot;)) +
  scale_size(range=c(1,11), guide=NULL) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;just-the-code&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Just the code&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cors &amp;lt;- function(df) {
  M &amp;lt;- Hmisc::rcorr(as.matrix(df))
  Mdf &amp;lt;- map(M, ~data.frame(.x))
  return(Mdf)
}

formatted_cors &amp;lt;- function(df){
  cors(df) %&amp;gt;%
    map(~rownames_to_column(.x, var=&amp;quot;measure1&amp;quot;)) %&amp;gt;%
    map(~pivot_longer(.x, -measure1, &amp;quot;measure2&amp;quot;)) %&amp;gt;%
    bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;%
    pivot_wider(names_from = id, values_from = value) %&amp;gt;%
    rename(p = P) %&amp;gt;%
    mutate(sig_p = ifelse(p &amp;lt; .05, T, F),
           p_if_sig = ifelse(p &amp;lt;.05, p, NA),
           r_if_sig = ifelse(r &amp;lt;.05, r, NA)) 
}

formatted_cors(mtcars) %&amp;gt;%
  ggplot(aes(measure1, measure2, fill=r, label=round(r_if_sig,2))) +
  geom_tile() +
  labs(x = NULL, y = NULL, fill = &amp;quot;Pearson&amp;#39;s\nCorrelation&amp;quot;, title=&amp;quot;Correlations in Mtcars&amp;quot;,
       subtitle=&amp;quot;Only significant Pearson&amp;#39;s correlation coefficients shown&amp;quot;) +
  scale_fill_gradient2(mid=&amp;quot;#FBFEF9&amp;quot;,low=&amp;quot;#0C6291&amp;quot;,high=&amp;quot;#A63446&amp;quot;, limits=c(-1,1)) +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  theme(text=element_text(family=&amp;quot;Roboto&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/corr-plots/corr-plots_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tips and Tricks from the New York R Conference</title>
      <link>/blog/nyrconf/nyr-conf-2019/</link>
      <pubDate>Sat, 01 Jun 2019 21:13:14 -0500</pubDate>
      <guid>/blog/nyrconf/nyr-conf-2019/</guid>
      <description>


&lt;p&gt;In early May I attended the &lt;a href=&#34;https://www.rstats.nyc/&#34;&gt;New York R Conference&lt;/a&gt;. There were 24 speakers, including my coworker at Weill Cornell Medicine, Elizabeth Sweeney! Each person did a 20-minute presentation on some way they use R for their work and/or hobbies. There was a &lt;em&gt;ton&lt;/em&gt; of information, and even though not all of it was directly useful for my workflow as a statistical consultant in an academic setting, I really enjoyed being around so many people who love R.&lt;/p&gt;
&lt;p&gt;I’ve linked some videos of my favorite talks and put together some the topics/packages/functions I found most intriguing or useful in my day-to-day work as a research biostatistician. (This was originally a presentation for my &lt;a href=&#34;https://wcm-computing-club.github.io/&#34;&gt;biostatistics team’s computing club&lt;/a&gt;.)&lt;/p&gt;
&lt;div id=&#34;visualizing-data-with-naniar&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualizing data with &lt;code&gt;naniar&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Brooke Watson, a data scientist at the American Civil Liberties Union, gave a great presentation on how she uses R to defend immigrants. She shared several data wrangling tips. One new function for me was &lt;code&gt;naniar::vis_miss()&lt;/code&gt; to visualize your missing data quickly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;tidyverse&amp;quot;)
#install.packages(&amp;quot;naniar&amp;quot;)
library(tidyverse)
library(naniar)
vis_miss(airquality) # a base R data set&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/nyrconf/nyr-conf-2019_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It returns a &lt;code&gt;ggplot2&lt;/code&gt; object so you can edit titles, colors, etc. if necessary. You can also add various sorting and clustering arguments to make it easier to see patterns of missingness in your data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-out-data-differences-with-daff&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking out data differences with &lt;code&gt;daff&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Brooke also gave a demo for a neat package to check if and where differences in two data sets are occurring.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;daff)
library(daff)
dat1 &amp;lt;- data.frame(A = c(1:3), B = c(T,F,T))
dat2 &amp;lt;- data.frame(A = c(1:4), C = c(&amp;quot;apple&amp;quot;,NA,NA,&amp;quot;banana&amp;quot;))
my_diff &amp;lt;- diff_data(dat1, dat2)
my_diff&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Daff Comparison: &amp;#39;dat1&amp;#39; vs. &amp;#39;dat2&amp;#39; 
##       +++    ---  
## @@  A C      B    
## +   1 apple  TRUE 
##     2 &amp;lt;NA&amp;gt;   FALSE
##     3 &amp;lt;NA&amp;gt;   TRUE 
## +++ 4 banana &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;!-- {{ --&gt;
&lt;!-- &lt;figure src = &#34;diff_screenshot.png&#34; title=&#34;A caption&#34; lightbox=&#34;true&#34;&gt; --&gt;
&lt;!-- }} --&gt;
&lt;p&gt;I thought this would be useful for when you receive new data sets and want to make sure column names, patients, etc. haven’t changed. Check out the full documentation &lt;a href=&#34;https://github.com/edwindj/daff&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gohelverse&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Gohelverse&lt;/h1&gt;
&lt;p&gt;Noam Ross shared code for editable figures using David Gohel’s &lt;code&gt;officer&lt;/code&gt; and &lt;code&gt;rvg&lt;/code&gt; packages. I shared some &lt;a href=&#34;https://github.com/hoffmakl/reporting/blob/master/vg.R&#34;&gt;example code&lt;/a&gt; for my team on github after I saw him present it at an R-Ladies event in the fall. Essentially you can run some pretty simple lines of code to output figures (base R, &lt;code&gt;ggplot2&lt;/code&gt;, or otherwise) as editable figures in Powerpoint. Noam reminded us that whoever you give these figures to will now be able to edit &lt;em&gt;anything&lt;/em&gt;, even data points, so keep that in mind before you freely give away editable figures… :)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;rvg&amp;quot;)
#install.packages(&amp;quot;officer&amp;quot;)
library(rvg)
library(officer)

#sample data
dat &amp;lt;- data.frame(x = rnorm(100, 10),
                  y = rnorm(100, 100),
                  z = rnorm(100, 1))

#make an empty ppt
read_pptx() %&amp;gt;% 
  #add a slide, must specify the slide layout and layout name
  add_slide(layout=&amp;quot;Title and Content&amp;quot;, master=&amp;quot;Office Theme&amp;quot;) %&amp;gt;%
  #specify what you want on the slide (code = ...)
  #type=&amp;quot;body&amp;quot; means the plots going in the body part of the layout
  #width and height are in inches
  ph_with_vg(code = plot(dat$x, dat$y, main=&amp;quot;Edit me!&amp;quot;, pch=16), type=&amp;quot;body&amp;quot;, width=6, height=4) %&amp;gt;%
  #output your ppt (target argument is just the file destination/name)
  print(target=&amp;quot;plot.pptx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;going-from-rmarkdown-to-word-and-back-again-with-redoc&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Going from RMarkdown to Word, and back again with &lt;code&gt;redoc&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Noam also shared his new package, &lt;code&gt;redoc&lt;/code&gt;, which allows you to reload an Rmd-generated word file back into R as a modified Rmd file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/redoc.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is part of his goal to decrease the pain of “the valley of heartbreak.” &lt;img src=&#34;/img/valleyofheartbreak.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Installation command is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#remotes::install_github(&amp;quot;noamross/redoc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may need to update several packages to get it to run correctly, but after that the main commands are just &lt;code&gt;redoc&lt;/code&gt; and &lt;code&gt;dedoc&lt;/code&gt;. To see for yourself, try running my &lt;a href=&#34;https://github.com/hoffmakl/nyr-conf-comp-club/blob/master/redoc_example.Rmd&#34;&gt;github code&lt;/a&gt;, making some changes to your word doc, and reloading back into Rmarkdown with the &lt;code&gt;dedoc()&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pipelines-in-drake&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Pipelines in &lt;code&gt;drake&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;/img/drake.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This could definitely be an entire computing club presentation… but for long projects that you have to redo with new data often, &lt;code&gt;drake&lt;/code&gt; is becoming really popular. Amanda Dobbyn gave an awesome presentation and you can see her slides &lt;a href=&#34;https://aedobbyn.github.io/nyr-2019/#1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A super informative bookdown guide by the authors can be found &lt;a href=&#34;https://ropenscilabs.github.io/drake-manual/&#34;&gt;here&lt;/a&gt;.
Essentially their motto is “what gets done stays done” so that you are not redoing work you’ve already done in order to update your results. Yet, you’re still redoing what needs to be done in a reproducible way!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/drake_pipeline.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;git-merge-conflicts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Git merge conflicts&lt;/h1&gt;
&lt;p&gt;I went to a whole-day workshop on Git so if you’re interested in talking more about this let me know. &lt;em&gt;BUT&lt;/em&gt; the biggest thing I learned was that if you are ever using Git and find your code has strange characters like &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; HEAD followed by ======== and a long set of letters/numbers, this means you have a merge conflict. It’s meant to be a flag so you know where to fix the differences in your two files you’re trying to version control! I spent days struggling with this problem before, so I thought I’d pass the message along in case anyone runs into it someday. :)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;talks-to-check-out&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Talks to check out&lt;/h1&gt;
&lt;p&gt;Some of my favorite talks from the conference were…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?time_continue=4&amp;amp;v=33BzunEXEIE&#34;&gt;Emily Robinson’s&lt;/a&gt; accessible instructions for how to make a package with &lt;code&gt;usethis&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/embed/g2bQJIth1-I&#34;&gt;Jaqueline Nolis’&lt;/a&gt; &lt;strong&gt;really funny&lt;/strong&gt; talk on how neural nets aren’t actually hard at all&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/embed/ZmbrsbYwRWw&#34;&gt;Andrew Gelman’s&lt;/a&gt; discussion on “solving all your statistical problems with p-values” (but he’s a Bayesian, ha ha)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;a-bonus&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A bonus!&lt;/h1&gt;
&lt;p&gt;This was not from the New York R Conference but I saw it on &lt;a href=&#34;https://twitter.com/OppenheimerEvan/status/1132092898760114184&#34;&gt;Twitter&lt;/a&gt; while making this presentation for my computing club and I really enjoyed it…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;genius&amp;quot;)
library(genius)
genius_lyrics(&amp;quot;the beatles&amp;quot;, &amp;quot;hey jude&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 53 x 3
##    track_title  line lyric                                           
##    &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                                           
##  1 Hey Jude        1 Hey Jude, don&amp;#39;t make it bad                     
##  2 Hey Jude        2 Take a sad song and make it better              
##  3 Hey Jude        3 Remember to let her into your heart             
##  4 Hey Jude        4 Then you can start to make it better            
##  5 Hey Jude        5 Hey Jude, don&amp;#39;t be afraid                       
##  6 Hey Jude        6 You were made to go out and get her             
##  7 Hey Jude        7 The minute you let her under your skin          
##  8 Hey Jude        8 Then you begin to make it better                
##  9 Hey Jude        9 And anytime you feel the pain, hey Jude, refrain
## 10 Hey Jude       10 Don&amp;#39;t carry the world upon your shoulders       
## # … with 43 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;takeaways&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Takeaways&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You can check out tweets from the conference by searching the hashtag &lt;a href=&#34;https://twitter.com/search?q=%23rstatsnyc&amp;amp;src=typed_query&#34;&gt;#rstatsnyc&lt;/a&gt; on Twitter&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check out the &lt;a href=&#34;https://www.meetup.com/rladies-newyork/&#34;&gt;R-Ladies NYC meetups&lt;/a&gt; and &lt;a href=&#34;https://www.meetup.com/nyhackr/&#34;&gt;New York R meetups&lt;/a&gt;!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Day in the Life of a Biostatistician</title>
      <link>/blog/ditl-biostats/</link>
      <pubDate>Tue, 16 Apr 2019 21:13:14 -0500</pubDate>
      <guid>/blog/ditl-biostats/</guid>
      <description>


&lt;p&gt;It seems fitting that my first blog post is on a topic that I tried and failed to find via Google search a few years ago.&lt;/p&gt;
&lt;p&gt;I’ll back up for a second. A few years ago I was a recent college graduate, and trying hard to “figure out my life.” My major was biochemistry, which is one of those degrees where 99%* of people just keep on going to school.&lt;/p&gt;
&lt;p&gt;I was working full-time night-shift at a hospital as a patient care technician. The key word in that sentence is “night-shift” which meant that even on my days off, I didn’t sleep at night, but all my friends and family did. So, I was often alone and awake, with a lot of time to think about my future… and surf the web for potential careers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/sadcat.png&#34; width=&#34;340px&#34; height=&#34;450px&#34; alt=&#34;cat&#34;&gt;&lt;/p&gt;
&lt;p&gt;I knew I wanted a job in healthcare, but I was confused as to where in medicine would be a good fit for me. I could visualize very clearly what my days at work would look like if I were to become a physician, or a physician assistant, or a registered nurse (all careers I developed lengthy pros and cons lists for).&lt;/p&gt;
&lt;p&gt;However, there was another career involving medicine that I was drawn to but didn’t know enough about. “Biostatistics” was a class biochemistry majors took at my university, but I had been exempted because I took AP Statistics in high school.&lt;/p&gt;
&lt;p&gt;To me, biostatistics seemed to be the application of some high school-level math to biological problems. I had no concept of what a degree in biostatistics, and much less a career as a biostatistician, could entail. Endless Google searches with some variant of “what does a biostatistician do” and even “day in the life of a biostatistician” had not given me a very good picture of what I would actually be doing as a biostatistician.&lt;/p&gt;
&lt;p&gt;I ultimately lucked out during a conversation with a professor during my senior year of college. I was rambling about my many life plans and he mentioned his cousin was the chair of a well-known Biostatistics program. He encouraged me to email her my questions about biostatistics, and I am so grateful she took time to respond with detailed answers. Her description of life as a biostatistician was enough for me to choose going to graduate school for an MS in biostatistics over medical school/physician assistant school/second-degree nursing.&lt;/p&gt;
&lt;p&gt;I feel wholeheartedly that although I would have enjoyed my life as an MD/PA/RN, biostatistics is the right career for me. So, in honor of my confused younger self, and as a way of paying it forward, I’ve dedicated this topic for my very first blog post!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/maz.png&#34; alt=&#34;ma&#34;width=&#34;400px&#34; height=&#34;400px&#34; &gt;&lt;/p&gt;
&lt;p&gt;A full disclaimer - what follows is a day in the life of one masters-level, academic research-focused biostatistician and I cannot make claims about the careers of statisticians in industry or pharmaceuticals or hospitals or government. In addition, here’s a bit more background before I get into the granular details of my work:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;My official job description is to assist investigators (i.e. physicians or PhD-level researchers with a scientific question) throughout all stages of the scientific research process. This means helping with study design, data collection, data cleaning (also known as getting the data in the right form for analysis and making sure nothing is obviously incorrect), data visualization, statistical analysis, reporting and explaining my results, and writing methods and results sections for scientific papers. You will soon see that on any given day I am working on multiple projects at various stages of this process.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I will mention R/Rstudio a bit. For those who are not familiar with it, &lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; is an open-source (which means anyone can help contribute) programming language that is well-equipped for statistical analysis. It’s arguably very similar to &lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt;, which is a more widely used language, but statisticians tend to use R more because its statistical packages are very well-developed. During grad school I used Python because I worked in a computational biology lab, and I learned &lt;a href=&#34;https://www.sas.com/en_us/home.html&#34;&gt;SAS&lt;/a&gt; (another statistical programming language) in some of my classes, but R is what I prefer these days. &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;Rstudio&lt;/a&gt; is a platform that makes it more user friendly to use R.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, without further ado! An average day**:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/desk.png&#34; width=&#34;500px&#34; height=&#34;375px&#34; alt=&#34;desky&#34;&gt;&lt;/p&gt;
&lt;p&gt;9:30AM - I arrive at my office and spend a few minutes chatting with my coworkers. To set the scene for you, I have a fairly spacious cubicle within a group of five other cubicles. I sit next to another research biostatistician, two health informatics professionals, and two clinical trial grant specialists. I’m actually not completely sure what that last pair’s title is, but I know their primary task is to make sure several multi-million dollar clinical trial grants stay funded (woah). Everyone I sit by is young and goofy, but very driven, making for a fun office environment.&lt;/p&gt;
&lt;p&gt;9:45AM - I check and answer new emails from researchers I collaborate on projects with. I send my availability for a meeting to a group of doctors who want to go over the results of a recent analysis I did on Body Mass Index and death rates in the Intensive Care Unit. In a different thread of emails, I thank several researchers from another university for clarifying their methods and sending me code for an analysis similar to one I will soon work on.&lt;/p&gt;
&lt;p&gt;10:00AM - I open a manuscript draft for a paper I received yesterday. It’s from a group of residents and medical students I worked with a few months ago. Their study looks at the association between blood levels of a certain biomarker and the time to death in cancer patients. My role in the analysis was to examine the associations between several biomarkers such as phosphorus, phosphate, and calcitriol. I then fit a regression model, just like y=mx+b, but with way more math. For this analysis I used a model for when your y is a time to an event (death, in this case), fittingly called a survival model. After adjusting for confounding factors like age, which affects both tumor progression and biomarker levels, there was a significant association between the biomarker and time to death in cancer patients.&lt;/p&gt;
&lt;p&gt;The researchers have asked for my assistance in writing the methods section. The methods section of a scientific article is the steps the scientists took to analyze data explicitly written out for anyone looking to review or learn about their work. I read through their current draft of the paper carefully, make some edits, and send it back. They are hoping to submit this paper to a peer-reviewed journal within a few weeks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/KM.png&#34; width=&#34;650px&#34; height=&#34;500px&#34; alt=&#34;kmplot&#34;&gt;&lt;/p&gt;
&lt;p&gt;10:45AM - I have a weekly meeting a few blocks from my office with a neurologist I spend a large portion of my time working with. She is a leader in the field of Alzheimer’s research, and I find it very rewarding to work on her data and be a small part of a growing body of research in the field. I am “contracted” out to her research as I am to all of the researchers I work with—it’s how my institution budgets funding for grants. One of the faculty-level biostatisticians in my department—which means he has a PhD and specializes in certain statistical methods—is also part of this contract, and some days, like today, he joins me at these meetings.&lt;/p&gt;
&lt;p&gt;11:00AM - This week’s meeting is pretty straightforward. We discuss how we can improve one of the neurologist’s National Institute of Health grants from a statistics standpoint. The statistical methods for this project can get complicated, in part because we are looking at the brain scans of women in different stages of menopause over time, and we have to consider age as a confounding factor. We want to convey to the reviewers of our grant how we plan to do this. Since this is a methods-focused meeting, I mostly listen and take notes along with two neurology research coordinators that also attend these weekly meetings. When the meeting concludes I have for less work than usual - I only need to make a few graphs representing our study design and past results for inclusion to the grant.&lt;/p&gt;
&lt;p&gt;12:00PM - I head to lunch with a group of coworkers. They have gotten food from a nearby salad place, and we sit in one of our favorite buildings on campus and eat together. Our jokes oscillate from incredibly nerdy to pretty stupid. One of my coworkers points out that our hair is styled the same way for the third day in a row.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/katalan.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;12:45PM - I get back to my desk and type up my handwritten notes from the neurology meeting and put them in that project’s “Notes” folder. It’s important to me that I keep track of all my meetings electronically - I fear losing my notebooks or someone else having to decipher my cursive should I ever have to pass off a project.&lt;/p&gt;
&lt;p&gt;1:00PM - I start to make a plan for a different analysis I’m working on. This project is something new for me - it involves a protein assay and data for 1000+ different protein expression levels. The researcher I’m working with wants to know which proteins are over- and under-expressed in people with a specific autoimmune disorder and a certain type of lung disease. I’ve recently spoken to some bioinformaticians and have a clearer idea of the analysis I need to do. I draw out a little map of the code organization I think would be the most efficient for this analysis and open up Rstudio.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/notes.jpg&#34; width=&#34;400px&#34; height=&#34;350px&#34; alt=&#34;notes&#34;&gt;&lt;/p&gt;
&lt;p&gt;1:30PM - I get to work writing up functions, which is just a fancy programming way of saying your code can do the same thing to multiple data sets (or subsets of patients, as is the case of this protein expression study I’m doing). Sometimes it takes a bit longer to write my functions than it would if I were to just copy and paste my code several different times, but the final code is much more readable and less prone to errors. By the time I’m done working, I have some interactive plots showing the significant and non-significant results. When you hover over them, they show what protein corresponds to which point on the graph. They look like this, except this is not the real data we used in her study.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/volcano.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I use Rstudio and its amazing Rmarkdown tool to craft a draft report to the researcher, and I save it with today’s date in my “Reports” folder for that project. The report so far includes unadjusted and adjusted models of all the protein expressions using very small p-values to account for the 1000+ statistical comparisons we’re making. I show the results in various plots such as the one above (called a “volcano plot” for its shape).&lt;/p&gt;
&lt;p&gt;I have also started writing code for models to determine which proteins are most different, or uniquely expressed, between subgroups of patients. Tomorrow, I will use a technique common in machine learning, called clustering, to see if these protein expressions can correctly classify subgroups of patients. The goal is to find a minimum group of proteins to identify patients of interest who have both the autoimmune disorder and the lung disease my collaborator is interested in. One way this research could be impactful is that it may help determine which proteins pharmaceuticals should develop drugs to target.&lt;/p&gt;
&lt;p&gt;I close the report; I will continue working on this analysis tomorrow.&lt;/p&gt;
&lt;p&gt;4:45PM - It’s time for my last meeting of the day. I head to another floor of my office building and get my laptop set up in a conference room. I await the arrival of several doctors. It will be my first time meeting most of them, and our task today is to discuss the data collection process for a future study involving both genetic mutation data from tumor biopsies and clinical data from electronic health records on thousands of patients with lung cancer.&lt;/p&gt;
&lt;p&gt;5:00PM - The doctors arrive and, after introductions, we talk about the current stage of the project and what the goals are. We discuss the timing of starting chart reviews of patients, how we will upload the information to a database efficiently, and what might be the best way to condense the highly detailed genetics data into useful information for an analysis. Our solution will likely involve a series of iterative searches through the columns containing genetic information.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/redcap.png&#34; alt=&#34;ma&#34;width=&#34;600px&#34; height=&#34;425px&#34; &gt;&lt;/p&gt;
&lt;p&gt;6:00PM - The meeting ends, and I go back to my desk to record more handwritten notes. I log the hours I spent on each project that day into Toggl, which is the time-tracking application our team uses. This is so we know how much time we’re spending on each project, and is as much for our own sake as it is anyone else’s. I update my to-do list, which is a giant color-coded excel spreadsheet, and eat a few chocolate covered raisins as my reward for a productive day.&lt;/p&gt;
&lt;p&gt;6:30PM - I leave work! I typically have some kind of activity, like happy hour (see my cute cubicle buddies below), a sports game, or Spanish class that I’m heading off to. Some days I attend coding workshops hosted by groups such as R-ladies. On nights when I’m feeling especially nerdy, I’ll go home and read a statistics paper or sift through the #rstats tips on twitter.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hoffmakl/khoffman_website/master/content/blog/coworkers.jpg&#34; width=&#34;500px&#34; height=&#34;375px&#34; alt=&#34;cowies&#34;&gt;&lt;/p&gt;
&lt;p&gt;…So, there you have it. One average daily experience as an early career masters-level statistician. All in all, I have a fantastic work-life balance and overall work environment. Every day I get to learn more about science, medicine, statistics, and the intersection of these wonderful ideas. Although it varies quite a bit, approximately 10% of each day involves writing, 20% interacting with other researchers, and the rest of it is spent thinking critically and finding answers to problems I am passionate about.&lt;/p&gt;
&lt;p&gt;I hope if there are any 22, 42, or 14 year-olds out there considering a career in biostatistics and struggling to figure out what on earth we actually do, that you find this post and it lessens your confusion! Feel free to reach out to me if you have questions.&lt;/p&gt;
&lt;p&gt;All the best,&lt;/p&gt;
&lt;p&gt;Kat&lt;/p&gt;
&lt;p&gt;*Not a real statistic.&lt;/p&gt;
&lt;p&gt;**Exact details and diseases of the studies I am currently working on have been generalized or altered to protect the research interests of my collaborators.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Wrangling with dplyr</title>
      <link>/blog/dplyr/data-wrangling/</link>
      <pubDate>Tue, 05 Mar 2019 21:13:14 -0500</pubDate>
      <guid>/blog/dplyr/data-wrangling/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;a-presentation-for-weill-cornell-medicines-biostatistics-computing-club&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A Presentation for Weill Cornell Medicine’s Biostatistics Computing Club&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/img/dplyr_image.jpg&#34; /&gt;
&lt;em&gt;Image courtesy of Allison Horst’s Twitter: &lt;span class=&#34;citation&#34;&gt;@allison_horst&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;div id=&#34;why-dplyr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why dplyr?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Powerful but efficient&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Consistent syntax&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fast&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Function chaining&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Works well with entire tidyverse suite&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Efficiency*&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Simple syntax&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Function chaining&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ability to analyze external databases&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Works well with other packages in tidyverse suite
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;ggplot2&lt;/li&gt;
&lt;li&gt;tidyr&lt;/li&gt;
&lt;li&gt;stringr&lt;/li&gt;
&lt;li&gt;forcats&lt;/li&gt;
&lt;li&gt;purrr&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;*if you start dealing with data sets with &amp;gt; 1 million rows, data.table will be much faster&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;iris&amp;quot;)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 3.2.1     ✔ purrr   0.3.2
## ✔ tibble  2.1.3     ✔ dplyr   0.8.3
## ✔ tidyr   0.8.3     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ───── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tibbles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tibbles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;An “update” to the data.frame object class in R&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Updates relevant for using dplyr:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Vectors of length 1 are automatically recycled&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Newly created vectors can be referenced in the same line of code&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Other perks: only the first 10 lines print to the screen so your console doesn’t get overloaded&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Read more about tibbles here: &lt;a href=&#34;https://r4ds.had.co.nz/tibbles.html&#34; class=&#34;uri&#34;&gt;https://r4ds.had.co.nz/tibbles.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;dplyr automatically converts objects to tbl_df (tibble data frame) objects&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;piping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Piping&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;%&amp;gt;%&lt;/code&gt; operator from &lt;code&gt;library(magitrr)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;%&amp;gt;%&lt;/code&gt; to send an object (typically a dataframe) to the next function&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The function you pipe to will use the object in front of the &lt;code&gt;%&amp;gt;%&lt;/code&gt; as its first argument&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% head() # equivalent to head(iris)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% head(n=3) # equivalent to head(iris, n=3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;If you don’t want it to be the first argument, use &lt;code&gt;.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% lm(Sepal.Width ~ Sepal.Length, data=.)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Sepal.Width ~ Sepal.Length, data = .)
## 
## Coefficients:
##  (Intercept)  Sepal.Length  
##      3.41895      -0.06188&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Shortcut for &lt;code&gt;%&amp;gt;%&lt;/code&gt; is CTRL + SHIFT + M (or CMD + SHIFT + M for OSX)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A function that takes a data frame as the first argument, eg. &lt;code&gt;head()&lt;/code&gt;, is called a &lt;strong&gt;verb&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The entire tidyverse suite operates under the verb function structure, making piping especially convenient&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;main-verbs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Main verbs&lt;/h1&gt;
&lt;div id=&#34;arrange&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;arrange()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sort data frame by column(s), lowest to highest&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(iris, Petal.Length) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1           4.6         3.6          1.0         0.2  setosa
## 2           4.3         3.0          1.1         0.1  setosa
## 3           5.8         4.0          1.2         0.2  setosa
## 4           5.0         3.2          1.2         0.2  setosa
## 5           4.7         3.2          1.3         0.2  setosa
## 6           5.4         3.9          1.3         0.4  setosa
## 7           5.5         3.5          1.3         0.2  setosa
## 8           4.4         3.0          1.3         0.2  setosa
## 9           5.0         3.5          1.3         0.3  setosa
## 10          4.5         2.3          1.3         0.3  setosa
## 11          4.4         3.2          1.3         0.2  setosa
## 12          5.1         3.5          1.4         0.2  setosa
## 13          4.9         3.0          1.4         0.2  setosa
## 14          5.0         3.6          1.4         0.2  setosa
## 15          4.6         3.4          1.4         0.3  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you specify a variable of class factor or character, you will rearrange the rows to alphabetical order&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;desc()&lt;/code&gt; if you want the opposite order&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(iris, desc(Species), # sort z to a since species is a factor
        Sepal.Width) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
## 1           6.0         2.2          5.0         1.5 virginica
## 2           4.9         2.5          4.5         1.7 virginica
## 3           6.7         2.5          5.8         1.8 virginica
## 4           5.7         2.5          5.0         2.0 virginica
## 5           6.3         2.5          5.0         1.9 virginica
## 6           7.7         2.6          6.9         2.3 virginica
## 7           6.1         2.6          5.6         1.4 virginica
## 8           5.8         2.7          5.1         1.9 virginica
## 9           6.4         2.7          5.3         1.9 virginica
## 10          6.3         2.7          4.9         1.8 virginica
## 11          5.8         2.7          5.1         1.9 virginica
## 12          5.8         2.8          5.1         2.4 virginica
## 13          5.6         2.8          4.9         2.0 virginica
## 14          7.7         2.8          6.7         2.0 virginica
## 15          6.2         2.8          4.8         1.8 virginica&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mutate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;mutate()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Add a new variable (while preserving all existing variables)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutate(iris, logSepLength = log(Sepal.Length)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species logSepLength
## 1           5.1         3.5          1.4         0.2  setosa     1.629241
## 2           4.9         3.0          1.4         0.2  setosa     1.589235
## 3           4.7         3.2          1.3         0.2  setosa     1.547563
## 4           4.6         3.1          1.5         0.2  setosa     1.526056
## 5           5.0         3.6          1.4         0.2  setosa     1.609438
## 6           5.4         3.9          1.7         0.4  setosa     1.686399
## 7           4.6         3.4          1.4         0.3  setosa     1.526056
## 8           5.0         3.4          1.5         0.2  setosa     1.609438
## 9           4.4         2.9          1.4         0.2  setosa     1.481605
## 10          4.9         3.1          1.5         0.1  setosa     1.589235
## 11          5.4         3.7          1.5         0.2  setosa     1.686399
## 12          4.8         3.4          1.6         0.2  setosa     1.568616
## 13          4.8         3.0          1.4         0.1  setosa     1.568616
## 14          4.3         3.0          1.1         0.1  setosa     1.458615
## 15          5.8         4.0          1.2         0.2  setosa     1.757858&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;There’s also &lt;code&gt;transmute()&lt;/code&gt; which deletes the old column(s) you use to make the new column&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% transmute(Length_diff = Sepal.Length - Petal.Length,
                   Width_diff = Sepal.Width - Petal.Width) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Length_diff Width_diff
## 1          3.7        3.3
## 2          3.5        2.8
## 3          3.4        3.0
## 4          3.1        2.9
## 5          3.6        3.4
## 6          3.7        3.5
## 7          3.2        3.1
## 8          3.5        3.2
## 9          3.0        2.7
## 10         3.4        3.0
## 11         3.9        3.5
## 12         3.2        3.2
## 13         3.4        2.9
## 14         3.2        2.9
## 15         4.6        3.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;filter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;filter()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Return rows matching specified conditions&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use with &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;!&lt;/code&gt;, &lt;code&gt;%in%&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, and &lt;code&gt;!=&lt;/code&gt;. Separating conditions by &lt;code&gt;,&lt;/code&gt; represents the &lt;code&gt;&amp;amp;&lt;/code&gt; argument.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% filter(Sepal.Length &amp;gt;= 2) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1           5.1         3.5          1.4         0.2  setosa
## 2           4.9         3.0          1.4         0.2  setosa
## 3           4.7         3.2          1.3         0.2  setosa
## 4           4.6         3.1          1.5         0.2  setosa
## 5           5.0         3.6          1.4         0.2  setosa
## 6           5.4         3.9          1.7         0.4  setosa
## 7           4.6         3.4          1.4         0.3  setosa
## 8           5.0         3.4          1.5         0.2  setosa
## 9           4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## 11          5.4         3.7          1.5         0.2  setosa
## 12          4.8         3.4          1.6         0.2  setosa
## 13          4.8         3.0          1.4         0.1  setosa
## 14          4.3         3.0          1.1         0.1  setosa
## 15          5.8         4.0          1.2         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% filter(Petal.Length &amp;gt;= mean(Petal.Length)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
## 1           7.0         3.2          4.7         1.4 versicolor
## 2           6.4         3.2          4.5         1.5 versicolor
## 3           6.9         3.1          4.9         1.5 versicolor
## 4           5.5         2.3          4.0         1.3 versicolor
## 5           6.5         2.8          4.6         1.5 versicolor
## 6           5.7         2.8          4.5         1.3 versicolor
## 7           6.3         3.3          4.7         1.6 versicolor
## 8           6.6         2.9          4.6         1.3 versicolor
## 9           5.2         2.7          3.9         1.4 versicolor
## 10          5.9         3.0          4.2         1.5 versicolor
## 11          6.0         2.2          4.0         1.0 versicolor
## 12          6.1         2.9          4.7         1.4 versicolor
## 13          6.7         3.1          4.4         1.4 versicolor
## 14          5.6         3.0          4.5         1.5 versicolor
## 15          5.8         2.7          4.1         1.0 versicolor&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% filter(Species != &amp;quot;versicolor&amp;quot;) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1           5.1         3.5          1.4         0.2  setosa
## 2           4.9         3.0          1.4         0.2  setosa
## 3           4.7         3.2          1.3         0.2  setosa
## 4           4.6         3.1          1.5         0.2  setosa
## 5           5.0         3.6          1.4         0.2  setosa
## 6           5.4         3.9          1.7         0.4  setosa
## 7           4.6         3.4          1.4         0.3  setosa
## 8           5.0         3.4          1.5         0.2  setosa
## 9           4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## 11          5.4         3.7          1.5         0.2  setosa
## 12          4.8         3.4          1.6         0.2  setosa
## 13          4.8         3.0          1.4         0.1  setosa
## 14          4.3         3.0          1.1         0.1  setosa
## 15          5.8         4.0          1.2         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% filter(Species %in% c(&amp;quot;versicolor&amp;quot;, &amp;quot;setosa&amp;quot;)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1           5.1         3.5          1.4         0.2  setosa
## 2           4.9         3.0          1.4         0.2  setosa
## 3           4.7         3.2          1.3         0.2  setosa
## 4           4.6         3.1          1.5         0.2  setosa
## 5           5.0         3.6          1.4         0.2  setosa
## 6           5.4         3.9          1.7         0.4  setosa
## 7           4.6         3.4          1.4         0.3  setosa
## 8           5.0         3.4          1.5         0.2  setosa
## 9           4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## 11          5.4         3.7          1.5         0.2  setosa
## 12          4.8         3.4          1.6         0.2  setosa
## 13          4.8         3.0          1.4         0.1  setosa
## 14          4.3         3.0          1.1         0.1  setosa
## 15          5.8         4.0          1.2         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;select&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;select()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Keep only specified variables&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, Sepal.Length, Sepal.Width) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width
## 1           5.1         3.5
## 2           4.9         3.0
## 3           4.7         3.2
## 4           4.6         3.1
## 5           5.0         3.6
## 6           5.4         3.9
## 7           4.6         3.4
## 8           5.0         3.4
## 9           4.4         2.9
## 10          4.9         3.1
## 11          5.4         3.7
## 12          4.8         3.4
## 13          4.8         3.0
## 14          4.3         3.0
## 15          5.8         4.0&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Specify variables to exclude with &lt;code&gt;-&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, -Species) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1           5.1         3.5          1.4         0.2
## 2           4.9         3.0          1.4         0.2
## 3           4.7         3.2          1.3         0.2
## 4           4.6         3.1          1.5         0.2
## 5           5.0         3.6          1.4         0.2
## 6           5.4         3.9          1.7         0.4
## 7           4.6         3.4          1.4         0.3
## 8           5.0         3.4          1.5         0.2
## 9           4.4         2.9          1.4         0.2
## 10          4.9         3.1          1.5         0.1
## 11          5.4         3.7          1.5         0.2
## 12          4.8         3.4          1.6         0.2
## 13          4.8         3.0          1.4         0.1
## 14          4.3         3.0          1.1         0.1
## 15          5.8         4.0          1.2         0.2&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Select a range of variables with &lt;code&gt;:&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, Sepal.Length:Petal.Length) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length
## 1           5.1         3.5          1.4
## 2           4.9         3.0          1.4
## 3           4.7         3.2          1.3
## 4           4.6         3.1          1.5
## 5           5.0         3.6          1.4
## 6           5.4         3.9          1.7
## 7           4.6         3.4          1.4
## 8           5.0         3.4          1.5
## 9           4.4         2.9          1.4
## 10          4.9         3.1          1.5
## 11          5.4         3.7          1.5
## 12          4.8         3.4          1.6
## 13          4.8         3.0          1.4
## 14          4.3         3.0          1.1
## 15          5.8         4.0          1.2&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;If you select just one column, you will still get a dataframe. If you need a vector, use &lt;code&gt;pull()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pull(iris, Sepal.Length) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summarise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;summarise()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Condenses data down to one value per group&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(iris, mean(Petal.Length)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean(Petal.Length)
## 1              3.758&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise(iris, sd_pl = sd(Petal.Length), var_pl = sd(Petal.Length)^2) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      sd_pl   var_pl
## 1 1.765298 3.116278&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;group_by&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;group_by()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Invisibly groups data by specified column(s)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use with other verbs to get grouped information&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% group_by(Species) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 5
## # Groups:   Species [1]
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  
##  1          5.1         3.5          1.4         0.2 setosa 
##  2          4.9         3            1.4         0.2 setosa 
##  3          4.7         3.2          1.3         0.2 setosa 
##  4          4.6         3.1          1.5         0.2 setosa 
##  5          5           3.6          1.4         0.2 setosa 
##  6          5.4         3.9          1.7         0.4 setosa 
##  7          4.6         3.4          1.4         0.3 setosa 
##  8          5           3.4          1.5         0.2 setosa 
##  9          4.4         2.9          1.4         0.2 setosa 
## 10          4.9         3.1          1.5         0.1 setosa 
## 11          5.4         3.7          1.5         0.2 setosa 
## 12          4.8         3.4          1.6         0.2 setosa 
## 13          4.8         3            1.4         0.1 setosa 
## 14          4.3         3            1.1         0.1 setosa 
## 15          5.8         4            1.2         0.2 setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;%
  group_by(Species) %&amp;gt;%
  summarise(mean(Petal.Length), sd(Petal.Length)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   Species    `mean(Petal.Length)` `sd(Petal.Length)`
##   &amp;lt;fct&amp;gt;                     &amp;lt;dbl&amp;gt;              &amp;lt;dbl&amp;gt;
## 1 setosa                     1.46              0.174
## 2 versicolor                 4.26              0.470
## 3 virginica                  5.55              0.552&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Data will remain grouped until you use &lt;code&gt;ungroup()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;rename&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;rename()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Give your columns new names. Syntax is newColumn = oldColumn.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% rename(sep_len = Sepal.Length) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    sep_len Sepal.Width Petal.Length Petal.Width Species
## 1      5.1         3.5          1.4         0.2  setosa
## 2      4.9         3.0          1.4         0.2  setosa
## 3      4.7         3.2          1.3         0.2  setosa
## 4      4.6         3.1          1.5         0.2  setosa
## 5      5.0         3.6          1.4         0.2  setosa
## 6      5.4         3.9          1.7         0.4  setosa
## 7      4.6         3.4          1.4         0.3  setosa
## 8      5.0         3.4          1.5         0.2  setosa
## 9      4.4         2.9          1.4         0.2  setosa
## 10     4.9         3.1          1.5         0.1  setosa
## 11     5.4         3.7          1.5         0.2  setosa
## 12     4.8         3.4          1.6         0.2  setosa
## 13     4.8         3.0          1.4         0.1  setosa
## 14     4.3         3.0          1.1         0.1  setosa
## 15     5.8         4.0          1.2         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;!-- * If you have weird characters in your column names, put ` signs around the old column name, not &#34; --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;helper-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Helper functions&lt;/h1&gt;
&lt;div id=&#34;everything&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;everything()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Move columns to the front of your data&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, Species, everything()) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Species Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1   setosa          5.1         3.5          1.4         0.2
## 2   setosa          4.9         3.0          1.4         0.2
## 3   setosa          4.7         3.2          1.3         0.2
## 4   setosa          4.6         3.1          1.5         0.2
## 5   setosa          5.0         3.6          1.4         0.2
## 6   setosa          5.4         3.9          1.7         0.4
## 7   setosa          4.6         3.4          1.4         0.3
## 8   setosa          5.0         3.4          1.5         0.2
## 9   setosa          4.4         2.9          1.4         0.2
## 10  setosa          4.9         3.1          1.5         0.1
## 11  setosa          5.4         3.7          1.5         0.2
## 12  setosa          4.8         3.4          1.6         0.2
## 13  setosa          4.8         3.0          1.4         0.1
## 14  setosa          4.3         3.0          1.1         0.1
## 15  setosa          5.8         4.0          1.2         0.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;starts_with&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;starts_with()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, starts_with(&amp;quot;Petal&amp;quot;)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Petal.Length Petal.Width
## 1           1.4         0.2
## 2           1.4         0.2
## 3           1.3         0.2
## 4           1.5         0.2
## 5           1.4         0.2
## 6           1.7         0.4
## 7           1.4         0.3
## 8           1.5         0.2
## 9           1.4         0.2
## 10          1.5         0.1
## 11          1.5         0.2
## 12          1.6         0.2
## 13          1.4         0.1
## 14          1.1         0.1
## 15          1.2         0.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ends_with&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;ends_with()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, ends_with(&amp;quot;Length&amp;quot;)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Petal.Length
## 1           5.1          1.4
## 2           4.9          1.4
## 3           4.7          1.3
## 4           4.6          1.5
## 5           5.0          1.4
## 6           5.4          1.7
## 7           4.6          1.4
## 8           5.0          1.5
## 9           4.4          1.4
## 10          4.9          1.5
## 11          5.4          1.5
## 12          4.8          1.6
## 13          4.8          1.4
## 14          4.3          1.1
## 15          5.8          1.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;contains&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;contains()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Searches column names for a specified string&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, contains(&amp;quot;Wid&amp;quot;)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Width Petal.Width
## 1          3.5         0.2
## 2          3.0         0.2
## 3          3.2         0.2
## 4          3.1         0.2
## 5          3.6         0.2
## 6          3.9         0.4
## 7          3.4         0.3
## 8          3.4         0.2
## 9          2.9         0.2
## 10         3.1         0.1
## 11         3.7         0.2
## 12         3.4         0.2
## 13         3.0         0.1
## 14         3.0         0.1
## 15         4.0         0.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matches&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;matches()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Searches column names for a specified regular expression&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(iris, matches(&amp;quot;wid|spec&amp;quot;)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Width Petal.Width Species
## 1          3.5         0.2  setosa
## 2          3.0         0.2  setosa
## 3          3.2         0.2  setosa
## 4          3.1         0.2  setosa
## 5          3.6         0.2  setosa
## 6          3.9         0.4  setosa
## 7          3.4         0.3  setosa
## 8          3.4         0.2  setosa
## 9          2.9         0.2  setosa
## 10         3.1         0.1  setosa
## 11         3.7         0.2  setosa
## 12         3.4         0.2  setosa
## 13         3.0         0.1  setosa
## 14         3.0         0.1  setosa
## 15         4.0         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more info on regex see &lt;a href=&#34;https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285&#34; title=&#34;here&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;row_number&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;row_number()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Specify which row number you want for your verb&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;%
  group_by(Species) %&amp;gt;%
  filter(row_number() == 1) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 5
## # Groups:   Species [3]
##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   
##          &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;     
## 1          5.1         3.5          1.4         0.2 setosa    
## 2          7           3.2          4.7         1.4 versicolor
## 3          6.3         3.3          6           2.5 virginica&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;n&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;n()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;References the number of rows in your data frame (or for each group in a &lt;code&gt;&#39;grouped_df&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;%
  group_by(Species) %&amp;gt;%
  filter(row_number() == n()) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 5
## # Groups:   Species [3]
##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   
##          &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;     
## 1          5           3.3          1.4         0.2 setosa    
## 2          5.7         2.8          4.1         1.3 versicolor
## 3          5.9         3            5.1         1.8 virginica&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;fancy-verbs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fancy verbs&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Scoped verbs take the additional arguments &lt;strong&gt;.predicate&lt;/strong&gt;, &lt;strong&gt;.funs&lt;/strong&gt;, and &lt;strong&gt;.vars&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;They end in &lt;code&gt;_at()&lt;/code&gt;, &lt;code&gt;_if()&lt;/code&gt; and &lt;code&gt;_all()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Signify what function (&lt;strong&gt;.funs&lt;/strong&gt;) should be applied too &lt;code&gt;all&lt;/code&gt; variables, only &lt;code&gt;at&lt;/code&gt; certain variables (&lt;strong&gt;.vars&lt;/strong&gt;), or only &lt;code&gt;if&lt;/code&gt; variables meet a certain condition (&lt;strong&gt;.predicate&lt;/strong&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ie. &lt;code&gt;mutate_at()&lt;/code&gt;, &lt;code&gt;mutate_if()&lt;/code&gt;, &lt;code&gt;mutate_all()&lt;/code&gt;, &lt;code&gt;summarise_if()&lt;/code&gt;, &lt;code&gt;summarise_at()&lt;/code&gt;, &lt;code&gt;summarise_all()&lt;/code&gt;, &lt;code&gt;select_if()&lt;/code&gt;, &lt;code&gt;select_at()&lt;/code&gt;, &lt;code&gt;rename_if()&lt;/code&gt;, &lt;code&gt;filter_all()&lt;/code&gt;, &lt;code&gt;arrange_all()&lt;/code&gt;, &lt;code&gt;group_by_at()&lt;/code&gt; …the list goes on!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A few examples (we will see more later)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% select_if(.predicate = is.numeric) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1           5.1         3.5          1.4         0.2
## 2           4.9         3.0          1.4         0.2
## 3           4.7         3.2          1.3         0.2
## 4           4.6         3.1          1.5         0.2
## 5           5.0         3.6          1.4         0.2
## 6           5.4         3.9          1.7         0.4
## 7           4.6         3.4          1.4         0.3
## 8           5.0         3.4          1.5         0.2
## 9           4.4         2.9          1.4         0.2
## 10          4.9         3.1          1.5         0.1
## 11          5.4         3.7          1.5         0.2
## 12          4.8         3.4          1.6         0.2
## 13          4.8         3.0          1.4         0.1
## 14          4.3         3.0          1.1         0.1
## 15          5.8         4.0          1.2         0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% select_if(.predicate = is.numeric, .funs=funs(paste0(&amp;quot;num_&amp;quot;,.))) %&amp;gt;% head(n=15) # can also be used to rename&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    num_Sepal.Length num_Sepal.Width num_Petal.Length num_Petal.Width
## 1               5.1             3.5              1.4             0.2
## 2               4.9             3.0              1.4             0.2
## 3               4.7             3.2              1.3             0.2
## 4               4.6             3.1              1.5             0.2
## 5               5.0             3.6              1.4             0.2
## 6               5.4             3.9              1.7             0.4
## 7               4.6             3.4              1.4             0.3
## 8               5.0             3.4              1.5             0.2
## 9               4.4             2.9              1.4             0.2
## 10              4.9             3.1              1.5             0.1
## 11              5.4             3.7              1.5             0.2
## 12              4.8             3.4              1.6             0.2
## 13              4.8             3.0              1.4             0.1
## 14              4.3             3.0              1.1             0.1
## 15              5.8             4.0              1.2             0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% summarise_if(.predicate = is.numeric, .funs = funs(mean(., na.rm=T))) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1     5.843333    3.057333        3.758    1.199333&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;% mutate_at(.vars = vars(c(&amp;quot;Sepal.Length&amp;quot;,&amp;quot;Petal.Length&amp;quot;)),
                                         .funs = funs(scale)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1   -0.89767388         3.5    -1.335752         0.2  setosa
## 2   -1.13920048         3.0    -1.335752         0.2  setosa
## 3   -1.38072709         3.2    -1.392399         0.2  setosa
## 4   -1.50149039         3.1    -1.279104         0.2  setosa
## 5   -1.01843718         3.6    -1.335752         0.2  setosa
## 6   -0.53538397         3.9    -1.165809         0.4  setosa
## 7   -1.50149039         3.4    -1.335752         0.3  setosa
## 8   -1.01843718         3.4    -1.279104         0.2  setosa
## 9   -1.74301699         2.9    -1.335752         0.2  setosa
## 10  -1.13920048         3.1    -1.279104         0.1  setosa
## 11  -0.53538397         3.7    -1.279104         0.2  setosa
## 12  -1.25996379         3.4    -1.222456         0.2  setosa
## 13  -1.25996379         3.0    -1.335752         0.1  setosa
## 14  -1.86378030         3.0    -1.505695         0.1  setosa
## 15  -0.05233076         4.0    -1.449047         0.2  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# z scores by Species for all numeric variables
iris %&amp;gt;% group_by(Species) %&amp;gt;%
  mutate_if(.predicate = is.numeric, .funs = funs(scale)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 5
## # Groups:   Species [1]
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  
##  1       0.267       0.190        -0.357      -0.436 setosa 
##  2      -0.301      -1.13         -0.357      -0.436 setosa 
##  3      -0.868      -0.601        -0.933      -0.436 setosa 
##  4      -1.15       -0.865         0.219      -0.436 setosa 
##  5      -0.0170      0.454        -0.357      -0.436 setosa 
##  6       1.12        1.25          1.37        1.46  setosa 
##  7      -1.15       -0.0739       -0.357       0.512 setosa 
##  8      -0.0170     -0.0739        0.219      -0.436 setosa 
##  9      -1.72       -1.39         -0.357      -0.436 setosa 
## 10      -0.301      -0.865         0.219      -1.39  setosa 
## 11       1.12        0.718         0.219      -0.436 setosa 
## 12      -0.584      -0.0739        0.795      -0.436 setosa 
## 13      -0.584      -1.13         -0.357      -1.39  setosa 
## 14      -2.00       -1.13         -2.08       -1.39  setosa 
## 15       2.25        1.51         -1.51       -0.436 setosa&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;I have never used any of the &lt;code&gt;group_by_*()&lt;/code&gt; but I imagine they’re useful when you have a large selection of identifiers/grouping variables that you can call easily with a predicate (for example, &lt;code&gt;is.factor&lt;/code&gt;). They can also be used with a &lt;strong&gt;.funs&lt;/strong&gt; argument as a shortcut to &lt;code&gt;group_by() %&amp;gt;% mutate()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;miscellaneous-verbs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Miscellaneous verbs&lt;/h1&gt;
&lt;div id=&#34;lag&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;lag()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Makes a new column with the value of one row previously&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;lead&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;lead()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Makes a new column with the value of one row ahead&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- runif(5)
cbind(ahead = lead(x), x, behind = lag(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           ahead          x    behind
## [1,] 0.47072787 0.78080563        NA
## [2,] 0.64402818 0.47072787 0.7808056
## [3,] 0.32345814 0.64402818 0.4707279
## [4,] 0.08515902 0.32345814 0.6440282
## [5,]         NA 0.08515902 0.3234581&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Can choose a time column to order your new values by with the argument &lt;code&gt;&#39;order_by&#39;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- df &lt;- data.frame(year = 2000:2005, value = (0:5) ^ 2) --&gt;
&lt;!-- df --&gt;
&lt;!-- scrambled &lt;- df[sample(nrow(df)), ] --&gt;
&lt;!-- scrambled --&gt;
&lt;!-- right &lt;- mutate(scrambled, prev = lag(value, order_by = year)) --&gt;
&lt;!-- arrange(right, year) --&gt;
&lt;!-- ``` --&gt;
&lt;ul&gt;
&lt;li&gt;Lag and lead are very useful for longitudinal models&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;complete&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;complete()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;incomplete_df &amp;lt;- data.frame(day = c(1,3,7,9), dose = c(0, 25, 40, 30)) %&amp;gt;% head(n=15)
incomplete_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   day dose
## 1   1    0
## 2   3   25
## 3   7   40
## 4   9   30&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;complete(incomplete_df, day = full_seq(1:max(day), 1)) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 2
##     day  dose
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     0
## 2     2    NA
## 3     3    25
## 4     4    NA
## 5     5    NA
## 6     6    NA
## 7     7    40
## 8     8    NA
## 9     9    30&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fill&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;fill()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fill in missing values with values before or after&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;incomplete_df %&amp;gt;%
  complete(day = full_seq(1:max(day), 1)) %&amp;gt;%
  fill(dose, .direction = &amp;quot;down&amp;quot;) %&amp;gt;% head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 2
##     day  dose
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     0
## 2     2     0
## 3     3    25
## 4     4    25
## 5     5    25
## 6     6    25
## 7     7    40
## 8     8    40
## 9     9    30&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;drop_na&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;drop_na()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;incomplete_df %&amp;gt;%
  complete(day = full_seq(1:max(day), 1)) %&amp;gt;%
  drop_na() %&amp;gt;% head(n=15) # when you have more variables, specify which columns you care about dropping NAs from&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##     day  dose
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     0
## 2     3    25
## 3     7    40
## 4     9    30&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sample_frac&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;sample_frac()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Randomly sample a specified fraction of rows of a data frame&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydat &amp;lt;- data.frame(id = sample(1:100, 20), meas = rnorm(20))
mydat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     id         meas
## 1   57  2.288186793
## 2  100 -1.602300385
## 3   46  0.609128605
## 4   85 -0.481366290
## 5   71 -0.333337018
## 6   99  0.551787362
## 7    5 -0.042839936
## 8   75 -0.803681418
## 9   67  0.904749782
## 10  23  0.333527940
## 11  77  0.040703715
## 12  33  0.002205167
## 13  37  0.943927491
## 14  41  1.027059802
## 15  64  1.005199118
## 16  62  0.591302764
## 17   3  1.262050643
## 18   7 -0.644000308
## 19  97 -0.768234573
## 20  45  0.698145334&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydat %&amp;gt;% sample_frac(size = .5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     id       meas
## 1   71 -0.3333370
## 2    3  1.2620506
## 3   75 -0.8036814
## 4   85 -0.4813663
## 5   45  0.6981453
## 6   64  1.0051991
## 7  100 -1.6023004
## 8   62  0.5913028
## 9   37  0.9439275
## 10  41  1.0270598&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydat %&amp;gt;% sample_frac(size= .5, replace = T) # you can also add sampling weights&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    id         meas
## 1  62  0.591302764
## 2  75 -0.803681418
## 3  33  0.002205167
## 4  97 -0.768234573
## 5  23  0.333527940
## 6  23  0.333527940
## 7  67  0.904749782
## 8  62  0.591302764
## 9  85 -0.481366290
## 10 75 -0.803681418&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sample_n&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;sample_n()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Randomly sample a specified number of rows of a data frame&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mydat %&amp;gt;% sample_n(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id      meas
## 1 62 0.5913028
## 2 37 0.9439275
## 3 41 1.0270598&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;joining-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Joining functions&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- data.frame(id = c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;), val = 1:3)
y &amp;lt;- data.frame(id = c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;D&amp;quot;), val = c(&amp;quot;T&amp;quot;,&amp;quot;F&amp;quot;,&amp;quot;T&amp;quot;))
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val
## 1  A   1
## 2  B   2
## 3  C   3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val
## 1  A   T
## 2  B   F
## 3  D   T&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;“Mutating” joins combine variables from the left and right hand sides ie. &lt;code&gt;full_join()&lt;/code&gt;, &lt;code&gt;inner_join()&lt;/code&gt;, &lt;code&gt;right_join()&lt;/code&gt;, and &lt;code&gt;left_join()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;full_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;full_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows and columns&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val.x val.y
## 1  A     1     T
## 2  B     2     F
## 3  C     3  &amp;lt;NA&amp;gt;
## 4  D    NA     T&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;inner_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;inner_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows from &lt;code&gt;x&lt;/code&gt; that have a match in &lt;code&gt;y&lt;/code&gt;, and all columns from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inner_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val.x val.y
## 1  A     1     T
## 2  B     2     F&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;left_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;left_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows from &lt;code&gt;x&lt;/code&gt; and all columns from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;left_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val.x val.y
## 1  A     1     T
## 2  B     2     F
## 3  C     3  &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;right_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;right_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows from &lt;code&gt;x&lt;/code&gt; and all columns from &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;right_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val.x val.y
## 1  A     1     T
## 2  B     2     F
## 3  D    NA     T&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;“Filtering” joins keep cases from the left hand side, ie. &lt;code&gt;semi_join()&lt;/code&gt; and &lt;code&gt;anti_join()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;semi_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;semi_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows in &lt;code&gt;x&lt;/code&gt; that have a match in &lt;code&gt;y&lt;/code&gt;, keeping only columns from &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;semi_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val
## 1  A   1
## 2  B   2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;anti_join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;anti_join()&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Return all rows from &lt;code&gt;x&lt;/code&gt; where there are not matching values in &lt;code&gt;y&lt;/code&gt;, keeping just the columns from &lt;code&gt;x&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anti_join(x, y, by = &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id val
## 1  C   3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;incorporating-dplyr-into-your-workflow&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Incorporating dplyr into your workflow&lt;/h1&gt;
&lt;div id=&#34;frequency-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequency Tables&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(kableExtra)
mtcars %&amp;gt;%
  group_by(vs, am) %&amp;gt;%
  summarise(n=n(), freq=n()/nrow(.)) %&amp;gt;%
  kable(caption=&amp;quot;Frequency Table of vs and am&amp;quot;, format=&amp;quot;html&amp;quot;) %&amp;gt;%
  kable_styling(c(&amp;quot;condensed&amp;quot;,&amp;quot;responsive&amp;quot;,&amp;quot;striped&amp;quot;,&amp;quot;hover&amp;quot;), full_width = F)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-condensed table-responsive table-striped table-hover&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-39&#34;&gt;Table 1: &lt;/span&gt;Frequency Table of vs and am
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
vs
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
am
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
n
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
freq
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.37500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.18750
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.21875
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.21875
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;comparegroups&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;compareGroups&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(compareGroups)
iris %&amp;gt;%
  mutate(Sepal.Length.Sq = Sepal.Length^2) %&amp;gt;%
  compareGroups(Species ~ ., data = .) %&amp;gt;%
  createTable() %&amp;gt;%
  export2md() %&amp;gt;%
  kable_styling(c(&amp;quot;condensed&amp;quot;,&amp;quot;responsive&amp;quot;,&amp;quot;striped&amp;quot;,&amp;quot;hover&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-condensed table table-condensed table-responsive table-striped table-hover&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-40&#34;&gt;Table 2: &lt;/span&gt;Summary descriptives table by groups of `Species’
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
setosa
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
versicolor
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
virginica
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p.overall
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-style: italic;border-bottom: 1px solid grey&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;font-style: italic;border-bottom: 1px solid grey&#34;&gt;
N=50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;font-style: italic;border-bottom: 1px solid grey&#34;&gt;
N=50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;font-style: italic;border-bottom: 1px solid grey&#34;&gt;
N=50
&lt;/td&gt;
&lt;td style=&#34;text-align:center;font-style: italic;border-bottom: 1px solid grey&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sepal.Length
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.01 (0.35)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.94 (0.52)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
6.59 (0.64)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sepal.Width
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3.43 (0.38)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.77 (0.31)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.97 (0.32)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Petal.Length
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.46 (0.17)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4.26 (0.47)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5.55 (0.55)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Petal.Width
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.25 (0.11)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.33 (0.20)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2.03 (0.27)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sepal.Length.Sq
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.2 (3.55)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
35.5 (6.16)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
43.8 (8.44)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;ggplotting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ggplotting&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;%
  filter(Species != &amp;quot;setosa&amp;quot;) %&amp;gt;%
  ggplot(aes(Sepal.Length, Petal.Width, col=Species)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/tutorial/dplyr/data-wrangling_files/figure-html/unnamed-chunk-41-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finding-columns-of-interest&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finding columns of interest&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When you have too many column names to look through manually, search for a string or pattern of strings&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;load(&amp;quot;dplyr_dat.Rdata&amp;quot;)
length(names(brain))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(brain, matches(&amp;quot;pib.*parietal.*&amp;quot;)) %&amp;gt;% names() # regex is not case sensitive&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;PIB.PET_AAL__Parietal_Inf_L&amp;quot;        
## [2] &amp;quot;PIB.PET_AAL__Parietal_Inf_R&amp;quot;        
## [3] &amp;quot;PIB.PET_AAL__Parietal_Sup_L&amp;quot;        
## [4] &amp;quot;PIB.PET_AAL__Parietal_Sup_R&amp;quot;        
## [5] &amp;quot;PIB.PET_FS__ctx.lh.inferiorparietal&amp;quot;
## [6] &amp;quot;PIB.PET_FS__ctx.lh.superiorparietal&amp;quot;
## [7] &amp;quot;PIB.PET_FS__ctx.rh.inferiorparietal&amp;quot;
## [8] &amp;quot;PIB.PET_FS__ctx.rh.superiorparietal&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;!-- * Create summary measures using variables of interest --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- brain %&gt;% --&gt;
&lt;!--   group_by(ID) %&gt;% --&gt;
&lt;!--   transmute(PIB_Parietal = mean(c(PIB.PET_AAL__Parietal_Inf_L, --&gt;
&lt;!--                                   PIB.PET_AAL__Parietal_Inf_R, --&gt;
&lt;!--                                   PIB.PET_AAL__Parietal_Sup_L, --&gt;
&lt;!--                                   PIB.PET_AAL__Parietal_Sup_R), na.rm=T)) %&gt;% --&gt;
&lt;!--   arrange(PIB_Parietal) --&gt;
&lt;!-- ``` --&gt;
&lt;/div&gt;
&lt;div id=&#34;missing-data-wrangling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Missing data wrangling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Add a column flagging a value as missing and then replace the missing values with the mean of the other values&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;misdat &amp;lt;- data.frame(x1 = sample(c(1:3, NA), 13, replace=T),
                     x2 = sample(c(-5:-2,NA), 13, replace=T))
misdat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x1 x2
## 1   3 -3
## 2   3 -5
## 3   3 -2
## 4  NA NA
## 5  NA -5
## 6  NA -2
## 7   1 -3
## 8   3 NA
## 9   1 -4
## 10 NA -3
## 11 NA -4
## 12  3 -5
## 13 NA -4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;misdat %&amp;gt;%
  mutate_all(.funs = funs(miss = ifelse(is.na(.), 1, 0))) %&amp;gt;%
  mutate_all(.funs = funs(replace_na(., mean(., na.rm=T))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1        x2 x1_miss x2_miss
## 1  3.000000 -3.000000       0       0
## 2  3.000000 -5.000000       0       0
## 3  3.000000 -2.000000       0       0
## 4  2.428571 -3.636364       1       1
## 5  2.428571 -5.000000       1       0
## 6  2.428571 -2.000000       1       0
## 7  1.000000 -3.000000       0       0
## 8  3.000000 -3.636364       0       1
## 9  1.000000 -4.000000       0       0
## 10 2.428571 -3.000000       1       0
## 11 2.428571 -4.000000       1       0
## 12 3.000000 -5.000000       0       0
## 13 2.428571 -4.000000       1       0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;longitudinal-data-wrangling-a&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Longitudinal data wrangling A&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Calculate the time since a patient was first admitted to the hospital&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;id &amp;lt;- c(1,1,1,2,2,2,2,3)
admit &amp;lt;- as.Date(c(&amp;quot;2017-06-22&amp;quot;, &amp;quot;2017-07-13&amp;quot;, &amp;quot;2017-08-29&amp;quot;,
                   &amp;quot;2017-04-01&amp;quot;, &amp;quot;2017-05-02&amp;quot;, &amp;quot;2017-11-14&amp;quot;, &amp;quot;2018-01-14&amp;quot;,
                   &amp;quot;2019-01-01&amp;quot;))
discharge &amp;lt;- as.Date(c(&amp;quot;2017-06-25&amp;quot;, &amp;quot;2017-07-31&amp;quot;, &amp;quot;2017-10-13&amp;quot;,
                   &amp;quot;2017-04-02&amp;quot;, &amp;quot;2017-05-10&amp;quot;, &amp;quot;2017-11-18&amp;quot;, &amp;quot;2018-02-12&amp;quot;,
                   &amp;quot;2019-01-05&amp;quot;))
hosp_dat &amp;lt;- data.frame(id, admit, discharge)
hosp_dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id      admit  discharge
## 1  1 2017-06-22 2017-06-25
## 2  1 2017-07-13 2017-07-31
## 3  1 2017-08-29 2017-10-13
## 4  2 2017-04-01 2017-04-02
## 5  2 2017-05-02 2017-05-10
## 6  2 2017-11-14 2017-11-18
## 7  2 2018-01-14 2018-02-12
## 8  3 2019-01-01 2019-01-05&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hosp_dat %&amp;gt;%
  group_by(id) %&amp;gt;%
  mutate(days_since_init_admit = discharge - admit[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 4
## # Groups:   id [3]
##      id admit      discharge  days_since_init_admit
##   &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;     &amp;lt;date&amp;gt;     &amp;lt;drtn&amp;gt;               
## 1     1 2017-06-22 2017-06-25   3 days             
## 2     1 2017-07-13 2017-07-31  39 days             
## 3     1 2017-08-29 2017-10-13 113 days             
## 4     2 2017-04-01 2017-04-02   1 days             
## 5     2 2017-05-02 2017-05-10  39 days             
## 6     2 2017-11-14 2017-11-18 231 days             
## 7     2 2018-01-14 2018-02-12 317 days             
## 8     3 2019-01-01 2019-01-05   4 days&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;longitudinal-data-wrangling-b&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Longitudinal data wrangling B&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Make a row for every patient for every month from the start of follow up to the end of follow up (get equally spaced time intervals)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make another column containing the drugs the patient was on previously (for prediction or longitudinal models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;load(&amp;quot;meds.Rdata&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    PatientID Months_ImplantToVisit BB_yn ACE_yn ARB_yn
## 1          1                     1     0      0      0
## 2          1                     2     0      0      0
## 3          2                     2     0      1      0
## 4          2                     3     0      1      0
## 5          2                     4     0      1      0
## 6          2                     5     0      1      0
## 7          2                     6     1      1      0
## 8          2                     8     1      1      0
## 9          2                    10     1      1      0
## 10         2                    12     1      1      0
## 11         2                    13     1      1      0
## 12         2                    14     1      1      0
## 13         2                    16     1      1      0
## 14         3                     2     0      0      0
## 15         3                     3     0      0      0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meds %&amp;gt;%
    group_by(PatientID) %&amp;gt;%
    complete(Months_ImplantToVisit = full_seq(1:max(Months_ImplantToVisit), 1)) %&amp;gt;%
    fill(ends_with(&amp;quot;_yn&amp;quot;)) %&amp;gt;%
    fill(ends_with(&amp;quot;_yn&amp;quot;), .direction=&amp;quot;up&amp;quot;) -&amp;gt; meds1
meds1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 21 x 5
## # Groups:   PatientID [3]
##    PatientID Months_ImplantToVisit BB_yn ACE_yn ARB_yn
##        &amp;lt;int&amp;gt;                 &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; 
##  1         1                     1 0     0      0     
##  2         1                     2 0     0      0     
##  3         2                     1 0     1      0     
##  4         2                     2 0     1      0     
##  5         2                     3 0     1      0     
##  6         2                     4 0     1      0     
##  7         2                     5 0     1      0     
##  8         2                     6 1     1      0     
##  9         2                     7 1     1      0     
## 10         2                     8 1     1      0     
## # … with 11 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meds1 %&amp;gt;%
  mutate_at(.vars = vars(ends_with(&amp;quot;_yn&amp;quot;)),
              .funs = funs(prev = lag(., order_by = Months_ImplantToVisit))) %&amp;gt;%
    fill(ends_with(&amp;quot;_prev&amp;quot;), .direction=&amp;quot;up&amp;quot;) %&amp;gt;%
  head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 8
## # Groups:   PatientID [2]
##    PatientID Months_ImplantT… BB_yn ACE_yn ARB_yn BB_yn_prev ACE_yn_prev
##        &amp;lt;int&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt;      &amp;lt;fct&amp;gt;      
##  1         1                1 0     0      0      0          0          
##  2         1                2 0     0      0      0          0          
##  3         2                1 0     1      0      0          1          
##  4         2                2 0     1      0      0          1          
##  5         2                3 0     1      0      0          1          
##  6         2                4 0     1      0      0          1          
##  7         2                5 0     1      0      0          1          
##  8         2                6 1     1      0      0          1          
##  9         2                7 1     1      0      1          1          
## 10         2                8 1     1      0      1          1          
## 11         2                9 1     1      0      1          1          
## 12         2               10 1     1      0      1          1          
## 13         2               11 1     1      0      1          1          
## 14         2               12 1     1      0      1          1          
## 15         2               13 1     1      0      1          1          
## # … with 1 more variable: ARB_yn_prev &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;survival-data-wrangling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Survival data wrangling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Map four columns “days to…outcome” to a composite endpoint for a survival model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Record &lt;em&gt;when&lt;/em&gt; the event occurred as Days.to.first.event and &lt;em&gt;which&lt;/em&gt; event it was in FE.status&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dems %&amp;gt;%
  select(Days.to.lastFU, Days.to.death, Days.to.stroke, Days.to.GIB, Days.to.PT) %&amp;gt;%
  # which.min cannot handle NA, so we&amp;#39;ll make NA&amp;#39;s infinity for now
  replace(is.na(.), Inf) %&amp;gt;%
  # to allow which.min to search along rows (dplyr naturally looks down columns)
  rowwise() %&amp;gt;%
  mutate(
    FUorFEtime = pmin(Days.to.lastFU, Days.to.death, Days.to.stroke,
                      Days.to.GIB, Days.to.PT,
                      na.rm = T),
    # numbers correspond to order of the Days* columns
    FUorFEstatus = which.min(c(Days.to.lastFU, Days.to.death, Days.to.stroke,
                                    Days.to.GIB, Days.to.PT)),
    # condensed variable for survival model, 1 if any event
  Event_yn = ifelse(FUorFEstatus == 1, 0, 1)) -&amp;gt; dems_int

dems_int # look at the intermediate output&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [265 x 8]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 265 x 8
##    Days.to.lastFU Days.to.death Days.to.stroke Days.to.GIB Days.to.PT
##             &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;          &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1             98            98             94         Inf        Inf
##  2            163           Inf            Inf         Inf        141
##  3            185           Inf            Inf         Inf        Inf
##  4            139           Inf            Inf         Inf        Inf
##  5            196           Inf            Inf          78        Inf
##  6            161           Inf            Inf         Inf        Inf
##  7            210           Inf            185         Inf        Inf
##  8            233           Inf            Inf         Inf        Inf
##  9            239           Inf            Inf         Inf        Inf
## 10            243           Inf            Inf         Inf        Inf
## # … with 255 more rows, and 3 more variables: FUorFEtime &amp;lt;dbl&amp;gt;,
## #   FUorFEstatus &amp;lt;int&amp;gt;, Event_yn &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dems_int %&amp;gt;%
  # column names correspond to the order of the columns, rename
  mutate(FUorFEstatus = case_when(FUorFEstatus == 1 ~ &amp;quot;censored&amp;quot;,
                                  FUorFEstatus == 2 ~ &amp;quot;death&amp;quot;,
                                  FUorFEstatus == 3 ~ &amp;quot;stroke&amp;quot;,
                                  FUorFEstatus == 4 ~ &amp;quot;gib&amp;quot;,
                                  FUorFEstatus == 5 ~ &amp;quot;pt&amp;quot;,
                                  TRUE ~ &amp;quot;error&amp;quot;)) %&amp;gt;%
  # not case sensitive
  select(contains(&amp;quot;fe&amp;quot;), Event_yn) %&amp;gt;%
  # allow for joining with no duplicate cols
  rownames_to_column() %&amp;gt;%
  full_join(dems %&amp;gt;% rownames_to_column()) %&amp;gt;%
  select(-rowname) -&amp;gt; dems_clean

# check to make sure everything worked
dems_clean %&amp;gt;% filter(FUorFEstatus == &amp;quot;error&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [0 x 55]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 0 x 55
## # … with 55 variables: FUorFEtime &amp;lt;dbl&amp;gt;, FUorFEstatus &amp;lt;chr&amp;gt;,
## #   Event_yn &amp;lt;dbl&amp;gt;, PatientID &amp;lt;int&amp;gt;, Year.of.Implant &amp;lt;int&amp;gt;, Outcome &amp;lt;int&amp;gt;,
## #   Days.to.lastFU &amp;lt;int&amp;gt;, Stroke &amp;lt;int&amp;gt;, Days.to.stroke &amp;lt;int&amp;gt;,
## #   TypeStroke &amp;lt;int&amp;gt;, Stroke_IA &amp;lt;int&amp;gt;, Days.to.IA.stroke &amp;lt;int&amp;gt;,
## #   TypeStroke_IA &amp;lt;int&amp;gt;, PT &amp;lt;int&amp;gt;, Days.to.PT &amp;lt;int&amp;gt;, GIB &amp;lt;int&amp;gt;,
## #   Days.to.GIB &amp;lt;int&amp;gt;, GIB_IA &amp;lt;int&amp;gt;, Days.to.GIB_IA &amp;lt;int&amp;gt;,
## #   Age.at.implant &amp;lt;int&amp;gt;, Sex &amp;lt;fct&amp;gt;, Race &amp;lt;int&amp;gt;, Caucasian &amp;lt;int&amp;gt;,
## #   AfibFlut &amp;lt;fct&amp;gt;, Smoking_Hx &amp;lt;fct&amp;gt;, DM &amp;lt;fct&amp;gt;, Ischemic &amp;lt;int&amp;gt;,
## #   HTN_Hx &amp;lt;fct&amp;gt;, Stroke_Hx &amp;lt;fct&amp;gt;, Pulmonary_Hx &amp;lt;fct&amp;gt;, ICD &amp;lt;fct&amp;gt;,
## #   IMCS &amp;lt;int&amp;gt;, DT &amp;lt;int&amp;gt;, Hb_pre &amp;lt;dbl&amp;gt;, PLT_pre &amp;lt;int&amp;gt;, INR_dx &amp;lt;dbl&amp;gt;,
## #   Creat_dx &amp;lt;dbl&amp;gt;, Height &amp;lt;dbl&amp;gt;, Weight &amp;lt;dbl&amp;gt;, BMI &amp;lt;dbl&amp;gt;, Speed &amp;lt;int&amp;gt;,
## #   PI &amp;lt;dbl&amp;gt;, Flow &amp;lt;dbl&amp;gt;, RVAD &amp;lt;fct&amp;gt;, IABP &amp;lt;fct&amp;gt;,
## #   Days.to.first.outpt.visit &amp;lt;int&amp;gt;, Days.to.IA.discharge &amp;lt;int&amp;gt;, EF &amp;lt;fct&amp;gt;,
## #   LVEDD &amp;lt;fct&amp;gt;, RV_Dysf &amp;lt;fct&amp;gt;, LDH_Dx &amp;lt;int&amp;gt;, eGFR &amp;lt;dbl&amp;gt;, AvgMAP &amp;lt;lgl&amp;gt;,
## #   Death &amp;lt;int&amp;gt;, Days.to.death &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dems_clean %&amp;gt;%
  head(n=15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Source: local data frame [15 x 55]
## Groups: &amp;lt;by row&amp;gt;
## 
## # A tibble: 15 x 55
##    FUorFEtime FUorFEstatus Event_yn PatientID Year.of.Implant Outcome
##         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;           &amp;lt;int&amp;gt;   &amp;lt;int&amp;gt;
##  1         94 stroke              1         1            2016       2
##  2        141 pt                  1         2            2016       7
##  3        185 censored            0         3            2016       7
##  4        139 censored            0         4            2016       6
##  5         78 gib                 1         5            2016       7
##  6        161 censored            0         6            2016       1
##  7        185 stroke              1         7            2016       7
##  8        233 censored            0         8            2016       7
##  9        239 censored            0         9            2016       7
## 10        243 censored            0        10            2016       7
## 11        248 censored            0        11            2016       7
## 12         51 pt                  1        12            2016       1
## 13         37 gib                 1        13            2016       7
## 14        261 censored            0        14            2016       7
## 15        265 censored            0        15            2016       7
## # … with 49 more variables: Days.to.lastFU &amp;lt;int&amp;gt;, Stroke &amp;lt;int&amp;gt;,
## #   Days.to.stroke &amp;lt;int&amp;gt;, TypeStroke &amp;lt;int&amp;gt;, Stroke_IA &amp;lt;int&amp;gt;,
## #   Days.to.IA.stroke &amp;lt;int&amp;gt;, TypeStroke_IA &amp;lt;int&amp;gt;, PT &amp;lt;int&amp;gt;,
## #   Days.to.PT &amp;lt;int&amp;gt;, GIB &amp;lt;int&amp;gt;, Days.to.GIB &amp;lt;int&amp;gt;, GIB_IA &amp;lt;int&amp;gt;,
## #   Days.to.GIB_IA &amp;lt;int&amp;gt;, Age.at.implant &amp;lt;int&amp;gt;, Sex &amp;lt;fct&amp;gt;, Race &amp;lt;int&amp;gt;,
## #   Caucasian &amp;lt;int&amp;gt;, AfibFlut &amp;lt;fct&amp;gt;, Smoking_Hx &amp;lt;fct&amp;gt;, DM &amp;lt;fct&amp;gt;,
## #   Ischemic &amp;lt;int&amp;gt;, HTN_Hx &amp;lt;fct&amp;gt;, Stroke_Hx &amp;lt;fct&amp;gt;, Pulmonary_Hx &amp;lt;fct&amp;gt;,
## #   ICD &amp;lt;fct&amp;gt;, IMCS &amp;lt;int&amp;gt;, DT &amp;lt;int&amp;gt;, Hb_pre &amp;lt;dbl&amp;gt;, PLT_pre &amp;lt;int&amp;gt;,
## #   INR_dx &amp;lt;dbl&amp;gt;, Creat_dx &amp;lt;dbl&amp;gt;, Height &amp;lt;dbl&amp;gt;, Weight &amp;lt;dbl&amp;gt;, BMI &amp;lt;dbl&amp;gt;,
## #   Speed &amp;lt;int&amp;gt;, PI &amp;lt;dbl&amp;gt;, Flow &amp;lt;dbl&amp;gt;, RVAD &amp;lt;fct&amp;gt;, IABP &amp;lt;fct&amp;gt;,
## #   Days.to.first.outpt.visit &amp;lt;int&amp;gt;, Days.to.IA.discharge &amp;lt;int&amp;gt;, EF &amp;lt;fct&amp;gt;,
## #   LVEDD &amp;lt;fct&amp;gt;, RV_Dysf &amp;lt;fct&amp;gt;, LDH_Dx &amp;lt;int&amp;gt;, eGFR &amp;lt;dbl&amp;gt;, AvgMAP &amp;lt;lgl&amp;gt;,
## #   Death &amp;lt;int&amp;gt;, Days.to.death &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;making-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Problem: dplyr doesn’t know what to do with quotes around the variable name, but you can’t put the column name into a function without quotes because R will try to find it as an object in your environment…&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Solution: relying on the rlang package (sym, !!, !!!, etc)
&lt;ul&gt;
&lt;li&gt;A good tutorial: &lt;a href=&#34;http://jonthegeek.com/2018/06/04/writing-custom-tidyverse-functions/&#34; class=&#34;uri&#34;&gt;http://jonthegeek.com/2018/06/04/writing-custom-tidyverse-functions/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;irisSummary &amp;lt;- function(group){
    iris %&amp;gt;%
      group_by(!!sym(group)) %&amp;gt;%
      summarise(mean(Sepal.Length), sd(Sepal.Length))
}

irisSummary(group = &amp;quot;Species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   Species    `mean(Sepal.Length)` `sd(Sepal.Length)`
##   &amp;lt;fct&amp;gt;                     &amp;lt;dbl&amp;gt;              &amp;lt;dbl&amp;gt;
## 1 setosa                     5.01              0.352
## 2 versicolor                 5.94              0.516
## 3 virginica                  6.59              0.636&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;irisScatPlot &amp;lt;- function(x, y){
    iris %&amp;gt;%
    ggplot(aes_string(x, y, col=&amp;quot;Species&amp;quot;)) +
    geom_point() -&amp;gt; p
  return(p)
}

irisScatPlot(x=&amp;quot;Sepal.Length&amp;quot;,y=&amp;quot;Petal.Length&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/tutorial/dplyr/data-wrangling_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
