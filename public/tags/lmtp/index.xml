<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lmtp | KHstats</title>
    <link>/tags/lmtp/</link>
      <atom:link href="/tags/lmtp/index.xml" rel="self" type="application/rss+xml" />
    <description>lmtp</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 10 Oct 2020 21:13:14 -0500</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>lmtp</title>
      <link>/tags/lmtp/</link>
    </image>
    
    <item>
      <title>An Illustrated Guide to the Targeted Maximum Likelihood Estimation (TMLE) Algorithm</title>
      <link>/blog/tmle/intro-to-tmle/</link>
      <pubDate>Sat, 10 Oct 2020 21:13:14 -0500</pubDate>
      <guid>/blog/tmle/intro-to-tmle/</guid>
      <description>


&lt;blockquote&gt;
&lt;p&gt;A beginner‚Äôs guide to understanding Targeted Maximum Likelihood Estimation (TMLE) via a step-by-step tutorial for estimating the Average Treatment Effect (ATE).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;
HTML Image as link
&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;a href=&#34;https://github.com/hoffmakl/CI-visual-guides/blob/master/visual-guides/TMLE.pdf&#34;&gt;
&lt;img alt=&#34;cheatsheet&#34; src=&#34;/img/TMLE.jpg&#34;
         width=100%&#34;&gt;
&lt;figcaption&gt;
&lt;em&gt;&lt;a href=&#34;&#34;&gt;T&lt;/a&gt;here is a condensed version of this tutorial as an 8.5x11&#34; pdf on my Github in case you would like to print it out for reference as you read more formal TMLE explanations.&lt;/em&gt;
&lt;/figcaption&gt;
&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;hr /&gt;
&lt;div id=&#34;tmle-in-three-sentences&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1. TMLE in three sentences üéØ&lt;/h1&gt;
&lt;p&gt;Targeted Maximum Likelihood Estimation (TMLE) is a general semiparametric estimation framework to &lt;strong&gt;estimate a statistical quantity of interest&lt;/strong&gt;. TMLE allows the use of &lt;strong&gt;machine learning&lt;/strong&gt; (ML) models which place &lt;strong&gt;minimal assumptions on the distribution of the data&lt;/strong&gt;. Unlike estimates normally obtained from ML, the &lt;strong&gt;final TMLE estimate will still have valid standard errors for statistical inference&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-analysts-motivation-for-learning-tmle&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2. An Analyst‚Äôs Motivation for Learning TMLE üë©üèº‚Äçüíª&lt;/h1&gt;
&lt;p&gt;When I graduated with my MS in Biostatistics two years ago, I had a mental framework of statistics and data science that I think is pretty common among new graduates. It went like this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;If the goal is &lt;span style=&#34;color: #3366ff;&#34;&gt;inference&lt;/span&gt;, use an &lt;span style=&#34;color: #3366ff;&#34;&gt;interpretable (usually parametric) model&lt;/span&gt; and explain the meaning behind the coefficients and their standard errors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the goal is &lt;span style=&#34;color: #cc0000;&#34;&gt;prediction&lt;/span&gt;, use a &lt;span style=&#34;color: #cc0000;&#34;&gt;flexible machine learning model&lt;/span&gt; and then look at performance metrics and variable importance.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This mentality changed drastically when I started learning about semiparametric estimation methods like TMLE in the context of causal inference. I quickly realized two flaws in this mental framework.&lt;/p&gt;
&lt;!-- &lt;html&gt; --&gt;
&lt;!--    &lt;head&gt; --&gt;
&lt;!--       &lt;title&gt;HTML Image as link&lt;/title&gt; --&gt;
&lt;!--    &lt;/head&gt; --&gt;
&lt;!--    &lt;body&gt; --&gt;
&lt;!--       &lt;a href=&#34;&#34;&gt; --&gt;
&lt;!--          &lt;img alt=&#34;cheatsheet&#34; src=&#34;/img/tmle/estimator.png&#34; --&gt;
&lt;!--                style=&#34;float:right; padding-left:20px;&#34; width=50%&#34;&gt; --&gt;
&lt;!--       &lt;/a&gt; --&gt;
&lt;!--    &lt;/body&gt; --&gt;
&lt;!-- &lt;/html&gt; --&gt;
&lt;p&gt;First, I was thinking about inference backwards: I was choosing a model based on my outcome type (binary, continuous, time-to-event, repeated measures) and then interpreting specific coefficients as my estimates of interest. Yet it makes way more sense to &lt;em&gt;first&lt;/em&gt; determine the statistical quantity, or &lt;strong&gt;estimand&lt;/strong&gt;, that best answers a scientific question, and &lt;em&gt;then&lt;/em&gt; use the method, or &lt;strong&gt;estimator&lt;/strong&gt;, best for suited for estimating it. This is the paradigm TMLE is based upon: we want to build an algorithm &lt;strong&gt;targeted to an estimand of interest&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;[/img/tmle/estimator.png]{width=50%}&lt;/p&gt;
&lt;p&gt;Second, I thought flexible, data-adaptive machine learning models could only be used for prediction, since they don‚Äôt have asymptotic properties for inference (i.e.¬†standard errors). However, certain semiparametric estimation methods like TMLE can actually use these models to obtain a final estimate that is closer to the target quantity than would be obtained using standard parametric models. This is because, unlike parametric models, most machine learning algorithms do not assume an underlying distribution of the data. The way we use the machine learning estimates in TMLE, surprisingly enough, yields &lt;strong&gt;known asymptotic properties of bias and variance&lt;/strong&gt; just like we see in parametric maximum likelihood estimation (e.g.¬†linear and logistic regression).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-the-visual-guide&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3. Why the Visual Guide? üé®&lt;/h1&gt;
&lt;p&gt;TMLE was developed in 2007 by Mark van der Laan at UC Berkeley, and it is slowly but surely starting to see more widespread use. Since learning about TMLE, I‚Äôve believed many more analysts with a skill set similar to mine &lt;em&gt;could&lt;/em&gt; be using TMLE, but perhaps find even the most introductory resources to be a bit daunting.&lt;/p&gt;
&lt;p&gt;I am a very applied thinker, and I‚Äôve tried to write this tutorial in the way I would have found most useful and accessible when I began learning about TMLE. Each step is accompanied by a non-rigorous explanation, an equation using the simplest notation possible, in-line &lt;code&gt;R&lt;/code&gt; code, and a small graphic representing the computation on a data frame or vector. This last piece is super important for me, because I remember best when I associate an image with what I‚Äôve learned.&lt;/p&gt;
&lt;p&gt;This tutorial is not meant to replace any of the excellent resources I used to learn TMLE, but rather to supplement them. I use the same mathematical notation as the TMLE literature to make it easier to move back and forth. I hope you find the way I think about the algorithm useful, but if not, consider checking out the &lt;a href=&#34;#references&#34;&gt;references&lt;/a&gt; I‚Äôve listed at the end. TMLE and other inference methods which allow machine learning are extremely powerful and will undoubtedly only grow in popularity in statistics and data science.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;is-tmle-causal-inference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;4. Is TMLE Causal Inference? ü§î&lt;/h1&gt;
&lt;p&gt;Although TMLE was developed for causal inference due to its many attractive statistical properties (&lt;a href=&#34;#properties-of-tmle-üìà&#34;&gt;discussed later&lt;/a&gt;), it cannot be considered causal inference by itself. Causal inference is a process that first requires &lt;strong&gt;causal assumptions&lt;/strong&gt; (not discussed here) before a statistical estimand can be interpreted causally.&lt;/p&gt;
&lt;p&gt;TMLE can be used to estimate various statistical estimands (odds ratio, risk ratio, mean outcome difference, etc.) even when causal assumptions are not met. TMLE is, as its name implies, simply a tool for estimation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In this tutorial I‚Äôll show a basic version of TMLE: estimating the mean difference in outcomes, adjusted for baseline confounders, for a binary outcome and binary treatment. Under causal assumptions, this is the Average Treatment Effect (ATE).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tmle-step-by-step-Ô∏è&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;5. TMLE, Step-by-Step üö∂üèΩ‚Äç‚ôÇÔ∏è&lt;/h1&gt;
&lt;p&gt;Let‚Äôs look at the algorithm step-by-step. As you‚Äôre reading, keep in mind that there are &lt;code&gt;R&lt;/code&gt; packages that will do this for you as easily as running a &lt;code&gt;glm()&lt;/code&gt; or &lt;code&gt;coxph()&lt;/code&gt; function. This tutorial is to help understand what‚Äôs going on behind-the-scenes.&lt;/p&gt;
&lt;p&gt;One quick note before we dive into the algorithm:&lt;/p&gt;
&lt;div id=&#34;superlearning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Superlearning&lt;/h3&gt;
&lt;p&gt;I use the ensemble learning method &lt;strong&gt;superlearning&lt;/strong&gt; (also known as ‚Äústacking‚Äù) to demonstrate TMLE. This is because superlearning is theoretically and empirically proven to yield the best results in TMLE.&lt;/p&gt;
&lt;p&gt;For a tutorial on superlearning, you can check out my &lt;a href=&#34;www.khstats.com/sl/superlearning&#34;&gt;previous blog post&lt;/a&gt;. If you‚Äôre new to superlearning/stacking, the necessary knowledge for this post is that it allows you to combine many statistical learning algorithms for prediction. When I use &lt;code&gt;SuperLearner()&lt;/code&gt; in the following example code, I could have used &lt;code&gt;glm()&lt;/code&gt;, &lt;code&gt;randomForest()&lt;/code&gt;, or any other parametric or non-parametric supervised learning algorithm.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;initial-set-up&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Initial set up&lt;/h3&gt;
&lt;p&gt;Let‚Äôs first load the necessary libraries and set a seed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # for data manipulation
library(kableExtra) # for table printing
library(SuperLearner) # for ensemble learning

set.seed(7) # for reproducible results&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let‚Äôs simulate a data set for demonstration of the algorithm. This data will have a very simple structure: a binary treatment, &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, binary outcome, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, and four confounders: &lt;span class=&#34;math inline&#34;&gt;\(W_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(W_2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(W_3\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(W_4\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/1_data_structure.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_data &amp;lt;- function(n){ 
    W1 &amp;lt;- rbinom(n, size=1, prob=0.2) # binary confounder
    W2 &amp;lt;- rbinom(n, size=1, prob=0.5) # binary confounder
    W3 &amp;lt;- round(runif(n, min=0, max=5)) # continuous confounder
    W4 &amp;lt;- round(runif(n, min=0, max=4)) # continuous confounder
    A  &amp;lt;- rbinom(n, size=1, prob= plogis(-0.2 + 0.2*W2 + 0.1*W3 + 0.3*W4 + 0.2*W1*W4)) # binary treatment depends on confounders
    Y &amp;lt;- rbinom(n, size=1, prob= plogis(-1 + A - 0.1*W1 + 0.2*W2 + 0.3*W3 - 0.1*W4 + 0.1*W2*W4)) # binary outcome depends on confounders
    return(tibble(W1, W2, W3, W4, A, Y))
}

n &amp;lt;- 50
dat_obs &amp;lt;- generate_data(n) # generate a data set with n observations

kable(head(dat_obs), digits=2, caption = &amp;quot;Simulated data set.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-2&#34;&gt;Table 1: &lt;/span&gt;Simulated data set.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
W1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
W2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
W3
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
W4
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Y
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As mentioned earlier, TMLE can estimate many different statistical estimands of interest. In this example, the statistical estimand is the mean difference in outcomes between those who received the treatment and those who did not, adjusting for confounders.&lt;/p&gt;
&lt;p&gt;Under causal inference assumptions, this could be identifiable as the Average Treatment Effect (ATE). Let‚Äôs pretend for this example that we previously met causal assumptions and call our statistical estimand, &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;, the ATE.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Psi = ATE = E_W[E[Y|A=1,W] - E[Y|A=0,W]]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At this point in set-up, we should also pick our statistical learning algorithms to combine when we use the superlearner to estimate the expected outcome and probability of treatment. Let‚Äôs use LASSO (&lt;code&gt;glmnet&lt;/code&gt;), random forests (&lt;code&gt;ranger&lt;/code&gt;), and Multivariate Adaptive Regression Splines (MARS) (&lt;code&gt;earth&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sl_libs &amp;lt;- c(&amp;#39;SL.glmnet&amp;#39;, &amp;#39;SL.ranger&amp;#39;, &amp;#39;SL.earth&amp;#39;) # a library of machine learning algorithms (penalized regression, random forests, and multivariate adaptive regression splines)&lt;/code&gt;&lt;/pre&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 1: Estimate the Outcome
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;The very first step of TMLE is to estimate the expected value of the outcome using treatment and confounders as predictors. We can use any regression model to estimate this, but it is best to use flexible machine learning models so that we don‚Äôt have assumptions on the underlying distribution of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This is what that looks like in mathematical notation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Q(A,W) = \mathrm{E}[Y|A,W]\]&lt;/span&gt;
We can think about this equation as a generic regression function in &lt;code&gt;R&lt;/code&gt; called &lt;code&gt;fit()&lt;/code&gt; with inputs in formula form: &lt;code&gt;Y ~ x1 + x2 + ...&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/2_outcome_fit.png&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In real &lt;code&gt;R&lt;/code&gt; code, we‚Äôll use the &lt;code&gt;SuperLearner()&lt;/code&gt; function to fit a weighted combination of multiple machine learning models (defined earlier in &lt;code&gt;sl_libs&lt;/code&gt;). This function takes the outcome &lt;code&gt;Y&lt;/code&gt; as a vector and a data frame &lt;code&gt;W_A&lt;/code&gt; as predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Y &amp;lt;- dat_obs$Y
W_A &amp;lt;- dat_obs %&amp;gt;% select(-Y) # remove the outcome to make a matrix of predictors (A, W1, W2, W3, W4) for SuperLearner
Q &amp;lt;- SuperLearner(Y = Y, # Y is the outcome vector
                  X = W_A, # W_A is the matrix of W1, W2, W3, W4, and A
                  family=binomial(), # specify we have a binary outcome
                  SL.library = sl_libs) # specify our superlearner library of LASSO, RF, and MARS&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: glmnet&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: earth&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required namespace: ranger&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we should predict the outcome for every observation under three different scenarios:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. If every observation received the treatment they &lt;em&gt;actually&lt;/em&gt; received.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can get this expected outcome estimate by simply calling &lt;code&gt;predict()&lt;/code&gt; on the model fit without specifying any new data.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{Q}(A,W) = \mathrm{\hat{E}}[Y|A,W]\]&lt;/span&gt;
We will assign that vector of predictions to a new object, &lt;code&gt;Q_A&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/3_QA.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q_A &amp;lt;- as.vector(predict(Q)$pred) # obtain predictions for everyone using the treatment they actually received&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. If every observation received the treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To do this, we‚Äôll first need to create a data set where every observation received the treatment of interest, whether they actually did or not. Then we can call the &lt;code&gt;predict()&lt;/code&gt; function on that data set.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{Q}(1,W) = \mathrm{\hat{E}}[Y|A=1,W]\]&lt;/span&gt;
Notice our treatment vector is now entirely red, because everyone was treated:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/4_Q1.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;W_A1 &amp;lt;- W_A %&amp;gt;% mutate(A = 1)  # data set where everyone received treatment
Q_1 &amp;lt;- as.vector(predict(Q, newdata = W_A1)$pred) # predict on that everyone-exposed data set&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3. If every observation received the control.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Similarly, we create a data set where every observation did &lt;em&gt;not&lt;/em&gt; receive the treatment of interest, whether they actually did or not, and call the &lt;code&gt;predict()&lt;/code&gt; function again.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{Q}(0,W) = \mathrm{\hat{E}}[Y|A=0,W]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/5_Q1.png&#34; style=&#34;width:80.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;W_A0 &amp;lt;- W_A %&amp;gt;% mutate(A = 0) # data set where no one received treatment
Q_0 &amp;lt;- as.vector(predict(Q, newdata = W_A0)$pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let‚Äôs create a new data frame, &lt;code&gt;dat_tmle&lt;/code&gt;, to hold the three vectors we‚Äôve created so far, along with the treatment status &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and observed outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Notice that when &lt;span class=&#34;math inline&#34;&gt;\(A=1\)&lt;/span&gt;, the expected outcome &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\hat{E}}[Y|A,W]\)&lt;/span&gt; equals the expected outcome under treatment &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\hat{E}}[Y|A=1,W]\)&lt;/span&gt; and when &lt;span class=&#34;math inline&#34;&gt;\(A=0\)&lt;/span&gt;, the expected outcome &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\hat{E}}[Y|A,W]\)&lt;/span&gt; equals the expected outcome under no treatment &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\hat{E}}[Y|A=0,W]\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_tmle &amp;lt;- tibble(Y = dat_obs$Y, A = dat_obs$A, Q_A, Q_0, Q_1)
kable(head(dat_tmle), digits=2, caption = &amp;quot;TMLE Algorithm after Step 1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-8&#34;&gt;Table 2: &lt;/span&gt;TMLE Algorithm after Step 1
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Also note that our expected outcomes are on the original outcome scale (i.e.¬†probability, rather than the &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; probability).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We could stop here and get our estimate of the ATE by computing &lt;code&gt;Q_1 - Q_0&lt;/code&gt;, which &lt;em&gt;would&lt;/em&gt; be the mean difference in the expected outcomes, conditional on confounders. However, those expected outcome estimates have the optimal bias-variance tradeoff for estimating the outcomes, not the ATE!&lt;/p&gt;
&lt;p&gt;That estimate of the ATE might be biased, and furthermore, we don‚Äôt have a formula to compute standard errors after using machine learning. We need to incorporate information about the treatment mechanism to fix this.&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 2: Estimate the Probability of Treatment
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;The next step is to estimate the probability of treatment, given confounders. This quantity is often called the &lt;strong&gt;propensity score&lt;/strong&gt;, as in it gives the &lt;em&gt;propensity&lt;/em&gt; that an observation will receive a treatment of interest.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[g(W) = \mathrm{Pr}(A=1|W)\]&lt;/span&gt;
&lt;img src=&#34;/img/tmle/6_treatment_fit.png&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We will estimate &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{Pr}(A=1|W)\)&lt;/span&gt; in the same way as we estimated &lt;span class=&#34;math inline&#34;&gt;\(E[Y|A,W]\)&lt;/span&gt;: using the superlearner algorithm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;A &amp;lt;- dat_obs$A
W &amp;lt;- dat_obs %&amp;gt;% select(-Y, -A) # matrix of predictors that only contains the confounders W1, W2, W3, and W4

g &amp;lt;- SuperLearner(Y = A,
                  X = W,
                  family=binomial(),
                  SL.library=sl_libs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we need to compute three different quantities from this model fit:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. The inverse probability of receiving treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H(1,W) = \frac{1}{g(W)} = \frac{1}{\mathrm{Pr}(A=1|W)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/7_H1.png&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g_w &amp;lt;- as.vector(predict(g)$pred)
H_1 &amp;lt;- 1/g_w&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. The negative inverse probability of not receiving treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H(0,W) = -\frac{1}{1-g(W)}= -\frac{1}{\mathrm{Pr}(A=0|W)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/8_H0.png&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;H_0 &amp;lt;- -1/(1-g_w)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3. If the observation was treated, the inverse probability of receiving treatment, and if they were not treated, the negative inverse probability of not receiving treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H(A,W) = \frac{\mathrm{I}(A=1)}{\mathrm{Pr}(A=1|W)}-\frac{\mathrm{I}(A=0)}{\mathrm{Pr}(A=0|W)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/9_HA.png&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To calculate this, we‚Äôll first add the &lt;span class=&#34;math inline&#34;&gt;\(H(1,W)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H(0,W)\)&lt;/span&gt; vectors to our &lt;code&gt;dat_tmle&lt;/code&gt; data frame, and then we can use &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; to assign &lt;span class=&#34;math inline&#34;&gt;\(H(A,W)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_tmle &amp;lt;- # add clever covariate data to dat_tmle
  dat_tmle %&amp;gt;%
  bind_cols(
         H_1 = H_1,
         H_0 = H_0) %&amp;gt;%
  mutate(H_A = case_when(A == 1 ~ H_1, # if A is 1 (treated), assign H_1
                       A == 0 ~ H_0))  # if A is 0 (not treated), assign H_0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have our initial estimates of the outcome, and the estimates of the probability of treatment:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(head(dat_tmle), digits=2, caption=&amp;quot;TMLE Algorithm after Step 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-13&#34;&gt;Table 3: &lt;/span&gt;TMLE Algorithm after Step 2
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Q_1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
H_1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
H_0
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
H_A
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.55
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.47
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-3.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We‚Äôll now use those vectors containing information about the treatment mechanism ‚Äì &lt;span class=&#34;math inline&#34;&gt;\(H(1,W)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H(0,W)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(H(A,W)\)&lt;/span&gt; ‚Äì to fix the wrong bias-variance trade-off for the expected outcome fits from Step 1.&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 3: Estimate the Fluctuation Parameter
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;To reiterate, in Step 1 we estimated the expected outcome, conditional on treatment and confounders. We know those machine learning fits have an optimal bias-variance trade-off for estimating the outcome (conditional on treatment and confounders), rather than the ATE. We will now use information about the treatment mechanism (from Step 2) to optimize the bias-variance trade-off for the ATE so we can obtain valid inference.&lt;/p&gt;
&lt;p&gt;Fair warning: this step is easy to code, but difficult to understand unless you have a background in semiparametric theory. I‚Äôll give a very brief high-level explanation, and then you can look at references if you‚Äôre curious to learn more. Importantly, &lt;strong&gt;the simple explanation I‚Äôm going to offer here is still &lt;em&gt;so much more&lt;/em&gt; than you need to know to appropriately implement TMLE as an applied statistician or data scientist.&lt;/strong&gt;&lt;/p&gt;
&lt;!-- Importantly, **fully understanding the math behind this step is not necessary to appropriately use TMLE.** --&gt;
&lt;p&gt;let‚Äôs quickly review/define some terms. Our &lt;strong&gt;estimand&lt;/strong&gt; of interest is the mean difference in outcomes, which we‚Äôre calling the ATE in this example (under the assumption that causal assumptions were met). There are many &lt;strong&gt;estimators&lt;/strong&gt; we could have used to obtain an &lt;strong&gt;estimate&lt;/strong&gt; of our estimand, but we‚Äôve chosen to use TMLE.&lt;/p&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;
HTML Image as link
&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;a href=&#34;&#34;&gt;
&lt;img alt=&#34;cheatsheet&#34; src=&#34;/img/bear_with_me.jpg&#34;
               style=&#34;float:right; padding-left:40px;&#34; width=50%&#34;&gt;
&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;Estimators can have&lt;/p&gt;
&lt;p&gt;Many estimators have &lt;strong&gt;estimating equations&lt;/strong&gt; to help them solve for their parameters. Maximum likelihood estimators like linear and logistic regression have an estimating equation (you may remember taking the derivative of the log-likelihood and setting it equal to zero to solve for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; in a statistics course), as does a Cox proportional hazards model. We don‚Äôt really think about them when we‚Äôre fitting a model, but they exist. We will set up an estimating equation for our TMLE estimator in this step. This estimating equation is constructed based on something called an &lt;strong&gt;efficient inluence function&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Estimands&lt;/p&gt;
&lt;p&gt;What we need do in this step is solve a certain &lt;strong&gt;estimating equation&lt;/strong&gt;. An estimating equation is just an umbrella term for an equation we set up to solve for something else. When you fit a linear or logistic regression, you set up an estimating equation behind the scenes (when you set the score function equal to zero) to get the coefficients.&lt;/p&gt;
&lt;p&gt;In this step, we construct an estimating equation that happens to solve for something called the &lt;strong&gt;Efficient Influence Function&lt;/strong&gt; (EIF) of the ATE. The EIF is a property some estimands have; it means they can be estimated &lt;strong&gt;efficiently&lt;/strong&gt; (achieving the smallest possible variance in the fewest number of observations).&lt;/p&gt;
&lt;p&gt;Because the ATE has an EIF, and because we‚Äôve set up an estimating equation to solve for the EIF, we will soon have the information to do two things:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Update our initial outcome estimates so that our ATE is asymptotically unbiased (under certain conditions, see the &lt;a href=&#34;#7-properties-of-tmle&#34;&gt;statistical properties section&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Construct a covariance matrix to get standard errors, confidence intervals, p-values, etc. for our estimate.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The EIF is the reason we‚Äôre able to use machine learning models ‚Äúunder the hood‚Äù while still obtaining asymptotic properties for inference.&lt;/p&gt;
&lt;p&gt;There is a &lt;em&gt;ton&lt;/em&gt; of math and theory behind that big picture explanation, but I‚Äôve described my favorite resources for learning more at the end of this post. Let‚Äôs take a look at the estimating equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[logit(\mathrm{E}[Y|A,W]) = logit(\mathrm{\hat{E}}[Y|A,W]) + \epsilon H(A,W)\]&lt;/span&gt;
How can we solve it? If we look at the left side, we can see it contains the true outcome &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, just &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; transformed.&lt;/p&gt;
&lt;p&gt;Luckily for us, there‚Äôs a well-known model that &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; transforms the left side of an equation: logistic regression. The estimating equation looks &lt;em&gt;a lot&lt;/em&gt; like a simple logistic regression, actually:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[logit(E[Y|X]) = \beta_0 + \beta_1 X\]&lt;/span&gt;
Do you see how our estimating equation &lt;em&gt;also&lt;/em&gt; has a vector on the right-hand side (&lt;span class=&#34;math inline&#34;&gt;\(H(A,W)\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;) with a corresponding coefficient (called &lt;span class=&#34;math inline&#34;&gt;\(epsilon\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;)? The only difference now is that the ‚Äúintercept‚Äù in our estimating equation, &lt;span class=&#34;math inline&#34;&gt;\(logit(\mathrm{\hat{E}}[Y|A,W])\)&lt;/span&gt; is not a constant value like&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;, it is a vector of values. We can see it as an &lt;strong&gt;offset&lt;/strong&gt; in a logistic regression, or a &lt;strong&gt;fixed intercept&lt;/strong&gt;, rather than a standard intercept.&lt;/p&gt;
&lt;p&gt;So to solve our estimating equation, we can leverage standard statistical software and fit a logistic regression with one covariate, &lt;span class=&#34;math inline&#34;&gt;\(H(A,W)\)&lt;/span&gt;, and the initial outcome estimate, &lt;span class=&#34;math inline&#34;&gt;\(logit(\mathrm{\hat{E}}[Y|A,W])\)&lt;/span&gt;, as a fixed intercept. The outcome of the logistic regression is the observed outcome, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;!-- If you think that‚Äôs crazy for me to say, I‚Äôd ask you to consider whether you know what estimating equation the Cox model is solving. If your answer is no, do you still feel comfortable running the `coxph()` in `R`? Yes, because understanding the estimating equation in a Cox model is not necessary to properly implement it! After this high-level why behind TMLE, you‚Äôre going to know more about TMLE than you do about the Cox model.  --&gt;
&lt;!-- We can figure out how much to change each outcome estimates by solving for something called the **Efficient Influence Function** (EIF) of the ATE. An Influence Function (IF) is a function that we can apply to our data that will tell us how much influence, or weight, each observation has on an estimate. The *Efficient* Influence Function is, similarly, the function that we can apply to our data to yield the smallest variance in the fewest possible observations. --&gt;
&lt;!-- If we worked through a mathematical proof, we could show that our ATE estimand has an EIF. If we worked through another proof, we could show that the following equation (using some of our already computed estimates) solves for a constant, $\epsilon$, which yields the EIF of the ATE: --&gt;
&lt;!-- We&#39;ll then use the information from this step to learn two separate but related things: --&gt;
&lt;!--   **A. How much the initial outcome estimates should change to yield an estimate that is closer to the true value of the ATE.** --&gt;
&lt;!--   **B. How much influence each observation has on the final estimate of the ATE.** This is how we&#39;ll compute the standard errors even after using machine learning fits in Step 1 and 2. --&gt;
&lt;!-- We can solve for the EIF of the ATE by estimating $\epsilon$ in this equation: --&gt;
&lt;p&gt;Two technical points for application: we use &lt;code&gt;qlogis&lt;/code&gt; to transform the probabilities &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\hat{E}}[Y|A,W]\)&lt;/span&gt; to the &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; scale. Also, the &lt;code&gt;R&lt;/code&gt; code for a fixed intercept is &lt;code&gt;-1 + offset(fixed_intercept)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/10_logistic_regression.png&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm_fit &amp;lt;- glm(Y ~ -1 + offset(qlogis(Q_A)) + H_A, data=dat_tmle, family=binomial)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note that this step has nothing to do with logistic regression, a logistic regression just happens to have the correct form for solving the estimating equation of the influence curve for the ATE estimand.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Next we need to save the coefficient from that logistic regression, which we will call &lt;span class=&#34;math inline&#34;&gt;\(\hat{\epsilon}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/11_epsilon.png&#34; style=&#34;width:40.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eps &amp;lt;- coef(glm_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the TMLE literature, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is called the &lt;strong&gt;fluctuation parameter&lt;/strong&gt;, because it provides information about how much to change, or fluctuate, our initial outcome estimates. Similarly, &lt;span class=&#34;math inline&#34;&gt;\(H(A,W)\)&lt;/span&gt; is called the &lt;strong&gt;clever covariate&lt;/strong&gt; because it ‚Äúcleverly‚Äù helps us solve for the EIF and then update our estimates.&lt;/p&gt;
&lt;p&gt;We will use both the fluctuation parameter and clever covariate in the next step to update our initial estimates of the expected outcome, conditional on confounders and treatment.&lt;/p&gt;
&lt;!-- The logistic regression in this case is unrelated to the outcome type; it is used because we want to solve for the log likelihood (remember in parametric MLE, you take the derivative of the log-likelihood to get the score...?) It&#39;s related to that. --&gt;
&lt;!-- **1. How much to change, or fluctuate, the initial estimates of the expected outcome.** We knew those initial outcome regressions were wrong, because their bias and variance were optimized for the outcome, not the effect of treatment. The fluctuation parameter, $\hat{\epsilon}$, combined with information about the treatment mechanism, $H(A,W)$, will help us update the outcomes to get closer to the true value of the final parameter, the ATE. --&gt;
&lt;!-- **2. How much influence each observation has on the final estimate.** The reason we&#39;re able to get standard errors for inference even after using data-adaptive machine learning algorithms like the superlearner is because the TMLE estimator has an EIF (not all estimators do). We&#39;ll be able to use it, just like we use the score function in parametric MLE, to estimate our standard errors. --&gt;
&lt;!-- There&#39;s a lot of semi-parametric theory behind this over-simplified explanation. If you&#39;re interested in learning more, I&#39;ve linked my favorite resources at the end of the post. --&gt;
&lt;!-- Intuitively, we do this step because we know the initial outcome estimates we used machine learning models to fit have the wrong bias-variance tradeoff for estimating the effect of treatment. We&#39;re trying to figure out how much we need to change those initial estimates of the outcome, using information about treatment, to achieve the correct bias-variance trade-off for our final statistical parameter of interest, the ATE.  --&gt;
&lt;!-- *Note that $H(A,W)$ is often referred to as the **clever covariate** in TMLE literature because it &#34;cleverly&#34; solves an important equation.* --&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 4: Update the Initial Estimates of the Expected Outcome
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;To update our expected outcome estimates, we first need to put the initial expected outcome estimates on the &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; scale using &lt;code&gt;qlogis()&lt;/code&gt; because that‚Äôs the scale we used to solve the fluctuation parameter in Step 3. Then we can add our update using the fluctuation parameter and clever covariate: &lt;span class=&#34;math inline&#34;&gt;\(\hat{\epsilon} \times H(A,W)\)&lt;/span&gt;. Finally, we can put the updated estimates back on the true outcome scale using &lt;code&gt;plogis()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note we can use &lt;span class=&#34;math inline&#34;&gt;\(expit\)&lt;/span&gt; to show the inverse of the &lt;span class=&#34;math inline&#34;&gt;\(logit\)&lt;/span&gt; function, and we will denote updates to the outcome regressions as &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathrm{E}}^*\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathrm{E}}\)&lt;/span&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Update the expected outcomes of all observations, given the treatment they actually received and their baseline confounders.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mathrm{E}}^*[Y|A,W] = expit(logit(\mathrm{\hat{E}}[Y|A,W]) + \hat{\epsilon}H(A,W))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/update_qAW.png&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;H_A &amp;lt;- dat_tmle$H_A # for cleaner code in Q_A_update
Q_A_update &amp;lt;- plogis(qlogis(Q_A) + eps*H_A)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. Update the expected outcomes, conditional on baseline confounders and everyone receiving the treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mathrm{E}}^*[Y|A=1,W] = expit(logit(\mathrm{\hat{E}}[Y|A=1,W]) + \hat{\epsilon}H(A,1))\]&lt;/span&gt;
&lt;img src=&#34;/img/tmle/12_update_Q1.png&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q_1_update &amp;lt;- plogis(qlogis(Q_1) + eps*H_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3. Update the expected outcomes, conditional on baseline confounders and no one receiving the treatment.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mathrm{E}}^*[Y|A=0,W] = expit(logit(\mathrm{\hat{E}}[Y|A=0,W]) + \hat{\epsilon}H(A,0))\]&lt;/span&gt;
&lt;img src=&#34;/img/tmle/13_update_Q0.png&#34; style=&#34;width:70.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q_0_update &amp;lt;- plogis(qlogis(Q_0) + eps*H_0)&lt;/code&gt;&lt;/pre&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 5: Compute the Statistical Estimand of Interest
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;We now have updated expected outcomes estimates, so we can compute the ATE as the mean difference in the updated outcome estimates under treatment and no treatment:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\Psi} = \hat{ATE} = \hat{E}_W[\hat{E^*}[Y|A=1,W] - \hat{E^*}[Y|A=0,W]]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/14_compute_ATE.png&#34; style=&#34;width:60.0%&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmle_ate &amp;lt;- mean(Q_1_update - Q_0_update)
tmle_ate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2130771&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then say, &lt;em&gt;the average treatment effect was estimated to be 21.3%.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If causal assumptions were not met, we would say, &lt;em&gt;the proportion of observations who experienced the outcome, after adjusting for baseline confounders, was estimated to be 21.3% higher for those who received treatment compared to those who did not.&lt;/em&gt;&lt;/p&gt;
&lt;html&gt;
&lt;body&gt;
&lt;h2 style=&#34;color:navy&#34; &gt;
&lt;strong&gt;Step 6: Calculate the Standard Errors, Confidence Intervals, and P-values
&lt;/h1&gt;
&lt;/strong&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p&gt;To find the standard error (SE) of a TMLE estimate, we first compute the &lt;strong&gt;Influence Curve&lt;/strong&gt; (IC). This is what we solved for when we fit the logistic regression in Step 3; we wanted to find the &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; that solved for the Efficient Influence Function (EIF). The terms EIF and IC are, for most intents and purposes, used interchangably; the latter tends to refer to an estimate with actual data.&lt;/p&gt;
&lt;p&gt;Anyways, we can compute the IC for our estimate, which tells us how much influence each observation has on the estimate. This is the semi-parametric equivalent to the score function in parametric MLE.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{IC} = (Y-\hat{E^*}[Y|A,W])H(A,W) + \hat{E^*}[Y|A=1,W] - \hat{E^*}[Y|A=0,W] - \hat{ATE}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ic &amp;lt;- (Y - Q_A_update) * H_A + Q_1_update - Q_0_update - tmle_ate&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the IC, we can take the square-root of its variance divided by the number of observations to get the standard error of our estimate.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle/15_ses.png&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{SE} = \sqrt{\frac{var(\hat{IC})}{N}} \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmle_se &amp;lt;- sqrt(var(ic)/nrow(dat_obs))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the standard error, we can easily get the 95% confidence interval and p-value of our estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_low &amp;lt;- tmle_ate - 1.96*tmle_se
conf_high &amp;lt;- tmle_ate + 1.96*tmle_se

pval &amp;lt;- 2 * (1 - pnorm(abs(tmle_ate / tmle_se)))

kable(tibble(tmle_ate, conf_low, conf_high), digits=3, caption = &amp;quot;TMLE Estimate of the ATE&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-22&#34;&gt;Table 4: &lt;/span&gt;TMLE Estimate of the ATE
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
tmle_ate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
conf_low
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
conf_high
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.213
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.48
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Then we can successfully report our ATE as 0.213 (95% CI: -0.054, 0.48).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-tmle-package&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;6 Using the &lt;code&gt;tmle&lt;/code&gt; package&lt;/h1&gt;
&lt;p&gt;Luckily there are &lt;code&gt;R&lt;/code&gt; packages so that you don‚Äôt have to hand code TMLE yourself. &lt;code&gt;R&lt;/code&gt; packages to implement the TMLE algorithm include &lt;a href=&#34;https://www.jstatsoft.org/article/view/v051i13&#34;&gt;&lt;code&gt;tmle&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://tlverse.org/tlverse-handbook/tmle3.html&#34;&gt;&lt;code&gt;tmle3&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://www.jstatsoft.org/article/view/v081i01&#34;&gt;&lt;code&gt;ltmle&lt;/code&gt;&lt;/a&gt;, and &lt;a href=&#34;https://htmlpreview.github.io/?https://gist.githubusercontent.com/nt-williams/ddd44c48390b8d976fad71750e48d8bf/raw/45db700a02bf92e2a55790e60ed48266a97ca4e7/intro-lmtp.html&#34;&gt;&lt;code&gt;lmtp&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code using the original &lt;code&gt;tmle&lt;/code&gt; package‚Äôs &lt;code&gt;tmle()&lt;/code&gt; function is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tmle_fit &amp;lt;-
  tmle::tmle(Y = Y, # outcome vector
           A = A, # treatment vector
           W = W, # matrix of confounders W1, W2, W3, W4
           Q.SL.library = sl_libs, # superlearning libraries from earlier for outcome regression Q(A,W)
           g.SL.library = sl_libs) # superlearning libraries from earlier for treatment regression g(W)

tmle_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Additive Effect
##    Parameter Estimate:  0.22071
##    Estimated Variance:  0.021564
##               p-value:  0.13284
##     95% Conf Interval: (-0.067108, 0.50852) 
## 
##  Additive Effect among the Treated
##    Parameter Estimate:  0.26122
##    Estimated Variance:  0.020829
##               p-value:  0.070304
##     95% Conf Interval: (-0.021656, 0.54409) 
## 
##  Additive Effect among the Controls
##    Parameter Estimate:  0.19485
##    Estimated Variance:  0.02307
##               p-value:  0.19955
##     95% Conf Interval: (-0.10285, 0.49255)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get the same result (variation due to randomness in the machine learning models) in just a few lines of code: the estimate using the original &lt;code&gt;tmle&lt;/code&gt; package is 0.221 (95% CI: -0.067, 0.509).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;properties-of-tmle&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;7 Properties of TMLE üìà&lt;/h1&gt;
&lt;p&gt;TMLE is a &lt;strong&gt;doubly robust&lt;/strong&gt; estimator, which means that if either the regression to estimate the expected outcome, or the regression to estimate the probability of treatment, are correctly specified (formally, their bias goes to zero as sample size grows large, meaning they are &lt;strong&gt;consistent&lt;/strong&gt;), the final TMLE estimate will be consistent.&lt;/p&gt;
&lt;p&gt;If both regressions are consistent, the final estimate will reach the smallest possible sample variance in the fewest number of observations (formally: it will be &lt;strong&gt;efficient&lt;/strong&gt;). The reason we use superlearning for estimating the outcome and treatment models fits is to give us the best possible chance of having correctly specified models.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/tmle_props.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Besides allowing for the use of machine learning models which place minimal assumptions on the underlying distribution of data, TMLE is appealing because its estimates will always stay in the bounds of the original outcome. This is because it is part of a class of &lt;strong&gt;substitution estimators&lt;/strong&gt;. There is another class of semiparametric estimation methods in causal inference that are referred to as &lt;strong&gt;one-step estimators&lt;/strong&gt;, but they can sometimes yield final estimates that are outside the original outcome scale.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;If you‚Äôd like to learn more, I recommend the following resources:&lt;/p&gt;
&lt;div id=&#34;tmle&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;TMLE&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The paper I referred to most often while learning TMLE was &lt;a href=&#34;https://academic.oup.com/aje/article/185/1/65/2662306&#34;&gt;&lt;em&gt;Targeted Maximum Likelihood Estimation for Causal Inference in Observational Studies&lt;/em&gt;&lt;/a&gt; by Megan S. Schuler and Sherri Rose. It has a nice step-by-step written explanation and Figure 1 is a good summary of how TMLE compares to other common estimation methods in causal inference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I also really like the written explanations in the &lt;a href=&#34;https://link.springer.com/book/10.1007/978-1-4419-9782-1&#34;&gt;&lt;em&gt;Targeted Learning&lt;/em&gt;&lt;/a&gt; book by Mark van der Laan and Sherri Rose. The notation was too difficult for me to follow, but the words themselves make a lot of sense.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Miguel Luque wrote an &lt;a href=&#34;https://migariane.github.io/TMLE.nb.html&#34;&gt;excellent bookdown tutorial on TMLE&lt;/a&gt;, also with step-by-step &lt;code&gt;R&lt;/code&gt; code. It is more technical and thorough than my post, but still aimed at an applied audience.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;semiparametric-theory&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Semiparametric Theory&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Edward Kennedy has several well-written pieces on semiparametric estimation in causal inference. I recommend starting with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;His introductory paper on &lt;a href=&#34;https://arxiv.org/pdf/1709.06418.pdf&#34;&gt;Semiparametric Theory&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;His &lt;a href=&#34;http://www.ehkennedy.com/uploads/5/8/4/5/58450265/unc_2019_cirg.pdf&#34;&gt;slideshow tutorial&lt;/a&gt; &lt;em&gt;Nonparametric efficiency theory and machine learning in causal inference&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;influence-functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Influence Functions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;My favorite resource so far for learning specifically about influence functions has been &lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/00031305.2020.1717620&#34;&gt;Visually Communicating Influence Functions&lt;/a&gt; by Aaron Fisher and Edward Kennedy. However, this paper didn‚Äôt make sense to me until I worked through this &lt;a href=&#34;https://observablehq.com/@herbps10/one-step-estimators-and-pathwise-derivatives&#34;&gt;interactive tutorial&lt;/a&gt; by Herb Susmann. I suggest playing around with the interactive examples first, and then trying to work through the paper.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The derivation of the Efficient Influence Function (EIF) in TMLE is in the Appendix of &lt;a href=&#34;https://link.springer.com/book/10.1007/978-1-4419-9782-1&#34;&gt;&lt;em&gt;Targeted Learning&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;causal-inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Causal Inference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you want to learn more about the foundations of causal inference, I suggest &lt;a href=&#34;http://bayes.cs.ucla.edu/PRIMER/&#34;&gt;&lt;em&gt;Causal Inference in Statistics: A Primer&lt;/em&gt;&lt;/a&gt; by Judea Pearl and &lt;a href=&#34;https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/&#34;&gt;&lt;em&gt;What If&lt;/em&gt;&lt;/a&gt; (Part I) by Miguel Hernan and James Robins. These are both good starters for learning about the &lt;em&gt;identification&lt;/em&gt; side of causal inference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I also think the introductory chapters of the previously mentioned &lt;a href=&#34;https://link.springer.com/book/10.1007/978-1-4419-9782-1&#34;&gt;&lt;em&gt;Targeted Learning&lt;/em&gt;&lt;/a&gt; book do an excellent job of setting up the ‚Äúroadmap‚Äù of causal inference.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I‚Äôll continue to update this page with resources as I discover them.&lt;/p&gt;
&lt;p&gt;Feedback on this post is welcome, either from the new learners of TMLE or experts in causal inference. The best way to reach me is through &lt;a href=&#34;mailto:kathoffman.stats@gmail.com&#34;&gt;email&lt;/a&gt;. This is just a side hobby of mine, so please be patient with my response time. :-)&lt;/p&gt;
&lt;p&gt;Thank you to my colleague Iv√°n D√≠az for answering my many, many questions on TMLE, and to Miguel Luque for very helpful feedback on the visual guide.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tutorial-code-and-session-info&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tutorial code and session info&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # for data manipulation
library(kableExtra) # for table printing
library(SuperLearner) # for ensemble learning

set.seed(7) # for reproducible results

sl_libs &amp;lt;- c(&amp;#39;SL.glmnet&amp;#39;, &amp;#39;SL.ranger&amp;#39;, &amp;#39;SL.earth&amp;#39;) # a library of machine learning algorithms (penalized regression, random forests, and multivariate adaptive regression splines)

generate_data &amp;lt;- function(n){ 
    W1 &amp;lt;- rbinom(n, size=1, prob=0.3)
    W2 &amp;lt;- rbinom(n, size=1, prob=0.7)
    W3 &amp;lt;- runif(n, min=0, max=3)
    W4 &amp;lt;- runif(n, min=0, max=8)
    A  &amp;lt;- rbinom(n, size=1, prob= plogis(-2 + 0.3*W2 + 0.1*W3 + 0.3*W4 + 0.4*W2*W4))
    Y &amp;lt;- rbinom(n, size=1, prob= plogis(-0.5 + A -0.2*W1 + 0.4*W2 + 0.2*W4 + 0.3*W3 + 0.2*W2*W4))
    return(tibble(W1, W2, W3, W4, A, Y))
}

n &amp;lt;- 50
dat_obs &amp;lt;- generate_data(n) # generate a data set with n observations

Y &amp;lt;- dat_obs$Y
W_A &amp;lt;- dat_obs %&amp;gt;% select(-Y) # remove the outcome to make a matrix of predictors (A, W1, W2, W3, W4) for SuperLearner

### Step 1: Estimate Q
Q &amp;lt;- SuperLearner(Y = Y, # Y is the outcome vector
                  X = W_A, # W1, W2, W3, W4, and A is the matrix of predictors
                  family=binomial(), # specify we have a binary outcome
                  SL.library = sl_libs) # specify our superlearner library of LASSO, RF, and MARS
Q_A &amp;lt;- as.vector(predict(Q)$pred) # obtain predictions for everyone using the treatment they actually received
W_A1 &amp;lt;- W_A %&amp;gt;% mutate(A = 1)  # data set where everyone received treatment
Q_1 &amp;lt;- as.vector(predict(Q, newdata = W_A1)$pred) # predict on that everyone-exposed data set
W_A0 &amp;lt;- W_A %&amp;gt;% mutate(A = 0) # data set where no one received treatment
Q_0 &amp;lt;- as.vector(predict(Q, newdata = W_A0)$pred)
dat_tmle &amp;lt;- tibble(Y = dat_obs$Y, A = dat_obs$A, Q_A, Q_0, Q_1)

### Step 2: Estimate g and compute H(A,W)
A &amp;lt;- dat_obs$A
W &amp;lt;- dat_obs %&amp;gt;% select(-Y, -A) # matrix of predictors that only contains the confounders W1, W2, W3, and W4
g &amp;lt;- SuperLearner(Y = A,
                  X = W,
                  family=binomial(),
                  SL.library=sl_libs)
g_w &amp;lt;- as.vector(predict(g)$pred)
H_1 &amp;lt;- 1/g_w
H_0 &amp;lt;- -1/(1-g_w)
dat_tmle &amp;lt;- # add clever covariate data to dat_tmle
  dat_tmle %&amp;gt;%
  bind_cols(
         H_1 = H_1,
         H_0 = H_0) %&amp;gt;%
  mutate(H_A = case_when(A == 1 ~ H_1, # if A is 1 (treated), assign H_1
                       A == 0 ~ H_0))  # if A is 0 (not treated), assign H_0

### Step 3: Estimate fluctuation parameter
glm_fit &amp;lt;- glm(Y ~ -1 + offset(qlogis(Q_A)) + H_A, data=dat_tmle, family=binomial)
eps &amp;lt;- coef(glm_fit)

### Step 4: Update Q&amp;#39;s
H_A &amp;lt;- dat_tmle$H_A # for cleaner code in Q_A_update
Q_A_update &amp;lt;- plogis(qlogis(Q_A) + eps*H_A)
Q_1_update &amp;lt;- plogis(qlogis(Q_1) + eps*H_1)
Q_0_update &amp;lt;- plogis(qlogis(Q_0) + eps*H_0)

### Step 5: Compute ATE
tmle_ate &amp;lt;- mean(Q_1_update - Q_0_update)

### Step 6: compute standard error, CIs and pvals
ic &amp;lt;- (Y - Q_A_update) * H_A + Q_1_update - Q_0_update - tmle_ate
tmle_se &amp;lt;- sqrt(var(ic)/nrow(dat_obs))
conf_low &amp;lt;- tmle_ate - 1.96*tmle_se
conf_high &amp;lt;- tmle_ate + 1.96*tmle_se
pval &amp;lt;- 2 * (1 - pnorm(abs(tmle_ate / tmle_se)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] SuperLearner_2.0-26 nnls_1.4            kableExtra_1.1.0   
##  [4] forcats_0.5.0       stringr_1.4.0       dplyr_1.0.2        
##  [7] purrr_0.3.4         readr_1.3.1         tidyr_1.1.2        
## [10] tibble_3.0.4        ggplot2_3.3.2       tidyverse_1.3.0    
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.5         lubridate_1.7.9    lattice_0.20-38    plotmo_3.5.7      
##  [5] earth_5.1.2        assertthat_0.2.1   glmnet_3.0-2       digest_0.6.27     
##  [9] foreach_1.5.0      ranger_0.12.1      R6_2.5.0           cellranger_1.1.0  
## [13] backports_1.1.8    reprex_0.3.0       evaluate_0.14      httr_1.4.2        
## [17] highr_0.8          blogdown_0.19      pillar_1.4.6       TeachingDemos_2.12
## [21] rlang_0.4.8        readxl_1.3.1       rstudioapi_0.11    Matrix_1.2-18     
## [25] rmarkdown_2.1      webshot_0.5.2      munsell_0.5.0      broom_0.7.0       
## [29] compiler_3.6.3     modelr_0.1.6       xfun_0.19          pkgconfig_2.0.3   
## [33] shape_1.4.4        htmltools_0.4.0    tidyselect_1.1.0   bookdown_0.19     
## [37] codetools_0.2-16   tmle_1.4.0.1       fansi_0.4.1        viridisLite_0.3.0 
## [41] crayon_1.3.4       dbplyr_1.4.3       withr_2.2.0        cabinets_0.6.0    
## [45] grid_3.6.3         jsonlite_1.7.1     gtable_0.3.0       lifecycle_0.2.0   
## [49] DBI_1.1.0          magrittr_1.5       scales_1.1.1       cli_2.1.0         
## [53] stringi_1.5.3      fs_1.4.1           xml2_1.3.0         ellipsis_0.3.1    
## [57] generics_0.1.0     vctrs_0.3.4        Formula_1.2-3      iterators_1.0.12  
## [61] tools_3.6.3        glue_1.4.2         hms_0.5.3          plotrix_3.7-7     
## [65] yaml_2.2.1         colorspace_1.4-1   rvest_0.3.5        knitr_1.30        
## [69] haven_2.2.0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
